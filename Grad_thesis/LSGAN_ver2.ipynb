{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "76DG_1bf64GT",
    "outputId": "901d18fc-2089-4942-8535-d03b30a06363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "vkzAllIK66ms",
    "outputId": "95793c99-a6ac-40f6-c1fb-67f75a880de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46937,
     "status": "ok",
     "timestamp": 1547759210592,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "2L53fqQ67E7e",
    "outputId": "628e1b19-9b90-4407-f618-095ca2ce7572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPE7EzB96zyT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models, transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seq_net import weights_init, Generator, Discriminator\n",
    "import seq_modules as sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48895,
     "status": "ok",
     "timestamp": 1547759212587,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zO4Zlp_46zyY",
    "outputId": "c23f7c24-a098-4efd-e492-f1feb39cbee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14aadfff530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定\n",
    "workers = 0\n",
    "batch_size=64\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 200\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './Result/lsGAN'\n",
    "display_interval = 100\n",
    "\n",
    "# 保存先ディレクトリを作成\n",
    "try:\n",
    "    os.makedirs(outf, exist_ok=True)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "# 乱数のシード（種）を固定\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pS2Hwb06zyd"
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 128\n",
    "\n",
    "def make_dataset(datadir):\n",
    "    '''\n",
    "    convert sequence to vector array\n",
    "    1.init array all 0 (4*SEQ_LENGTH)\n",
    "    2.convert sequences (all 0 array) to vector array.\n",
    "    ex. ACCGAT =\n",
    "    0 0 0 0 0 0    1 0 0 0 1 0\n",
    "    0 0 0 0 0 0  → 0 1 1 0 0 0\n",
    "    0 0 0 0 0 0    0 0 0 1 0 0\n",
    "    0 0 0 0 0 0    0 0 0 0 0 1\n",
    "    '''\n",
    "    pos_seq = \"SRX356455.05_peak_seq_128.txt\"\n",
    "    # id      chr     start   end     seq\n",
    "    data = pd.read_csv(os.path.join(datadir, \"sequences\", pos_seq), sep=\"\\t\")\n",
    "    sequences = [] \n",
    "    classes = [] #positive or negative\n",
    "    for index, row in data[[\"id\", \"seq\"]].iterrows():\n",
    "        y = 1 #positive\n",
    "        seq_vector = seq2vector(row[\"seq\"])\n",
    "        if len(seq_vector) == 0:\n",
    "            continue\n",
    "        sequences.append(seq2vector(row[\"seq\"]))\n",
    "        classes.append(np.array(y))\n",
    "    return sequences, classes\n",
    "\n",
    "def seq2vector(seq):\n",
    "    if type(seq) is not str: # Case on Null sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = np.zeros((4, SEQ_LENGTH)) #initiallize 4*SEQ_LENGTH array all 0\n",
    "    flag = 0\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        s = seq[i]\n",
    "        if s == \"a\" or s == \"A\":\n",
    "            seq_array[0, i] = 1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"c\" or s == \"C\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = 1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"g\" or s == \"G\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = 1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"t\" or s == \"T\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = 1\n",
    "        else:\n",
    "            flag += 1\n",
    "    if len(seq) == flag: # Case on N sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = seq_array.astype(np.float32)\n",
    "    return seq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80045,
     "status": "ok",
     "timestamp": 1547759243762,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "Q3F_XWIE6zyg",
    "outputId": "be6f1ed4-58d5-4382-bf74-5df47583877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "datadir = \"data\"\n",
    "\n",
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transforms = transforms.Compose([\n",
    "            ToTensorOfTarget()\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        sample = self.transforms(sample)\n",
    "        target = self.targets[index]\n",
    "        target = self.transforms(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data 相当。\n",
    "X, y = make_dataset(datadir)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.01)\n",
    "\n",
    "\n",
    "sequence_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train),\n",
    "    'test': DatasetFolder(X_test, y_test)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEJXjMwVG_pO"
   },
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める配列をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=64\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86262,
     "status": "ok",
     "timestamp": 1547759249997,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "THWJ0sN36zyk",
    "outputId": "d949d121-77fa-4106-c4a8-39a52414fa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): ConvTranspose1d(100, 2048, kernel_size=(4,), stride=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ConvTranspose1d(2048, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer5): Sequential(\n",
      "      (0): ConvTranspose1d(128, 4, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 生成器G。ランダムベクトルから贋作配列を生成する\n",
    "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
    "netG.apply(weights_init)    # weights_init関数で初期化\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86685,
     "status": "ok",
     "timestamp": 1547759250430,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zIsEJjBi6zyn",
    "outputId": "15be38a4-b909-46fa-e9f0-f43285d3979b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): Conv1d(4, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Conv1d(1024, 2048, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer5): Conv1d(2048, 1, kernel_size=(4,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 識別器D。配列が、元配列か贋作配列かを識別する\n",
    "netD = Discriminator(nch_d=nch_d).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abf1PyD96zyq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
    "\n",
    "# オプティマイザ−のセットアップ\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1,  device=device)  # 確認用の固定したノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1431,
     "status": "error",
     "timestamp": 1547757532865,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "dbEMPfif6zyt",
    "outputId": "86de345c-27ff-4713-bf12-91e13f2e0f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200][1/843] Loss_D: 0.112 Loss_G: 1.035 D(x): 0.863 D(G(z)): 0.169/-0.012\n",
      "[1/200][101/843] Loss_D: 0.025 Loss_G: 1.070 D(x): 0.937 D(G(z)): -0.043/-0.034\n",
      "[1/200][201/843] Loss_D: 0.023 Loss_G: 1.095 D(x): 0.971 D(G(z)): 0.043/-0.044\n",
      "[1/200][301/843] Loss_D: 0.141 Loss_G: 0.982 D(x): 0.839 D(G(z)): -0.226/0.022\n",
      "[1/200][401/843] Loss_D: 0.017 Loss_G: 0.975 D(x): 0.963 D(G(z)): 0.035/0.013\n",
      "[1/200][501/843] Loss_D: 0.006 Loss_G: 1.040 D(x): 1.001 D(G(z)): 0.025/-0.018\n",
      "[1/200][601/843] Loss_D: 0.084 Loss_G: 1.020 D(x): 1.046 D(G(z)): -0.066/-0.007\n",
      "[1/200][701/843] Loss_D: 0.085 Loss_G: 0.705 D(x): 0.867 D(G(z)): -0.086/0.195\n",
      "[1/200][801/843] Loss_D: 0.032 Loss_G: 0.792 D(x): 0.924 D(G(z)): -0.133/0.114\n",
      "epoch 1 D_loss is [0.07566195450643627]\n",
      "epoch 1 G_loss is [1.118073632001594]\n",
      "[2/200][1/843] Loss_D: 0.015 Loss_G: 1.008 D(x): 1.021 D(G(z)): -0.005/-0.001\n",
      "[2/200][101/843] Loss_D: 0.009 Loss_G: 0.948 D(x): 0.971 D(G(z)): -0.007/0.027\n",
      "[2/200][201/843] Loss_D: 0.133 Loss_G: 1.228 D(x): 1.056 D(G(z)): 0.056/-0.062\n",
      "[2/200][301/843] Loss_D: 0.019 Loss_G: 1.178 D(x): 1.028 D(G(z)): 0.099/-0.085\n",
      "[2/200][401/843] Loss_D: 0.014 Loss_G: 1.001 D(x): 0.996 D(G(z)): 0.008/0.003\n",
      "[2/200][501/843] Loss_D: 0.029 Loss_G: 1.045 D(x): 1.019 D(G(z)): -0.017/-0.019\n",
      "[2/200][601/843] Loss_D: 0.019 Loss_G: 1.261 D(x): 1.045 D(G(z)): 0.095/-0.119\n",
      "[2/200][701/843] Loss_D: 0.044 Loss_G: 0.910 D(x): 0.865 D(G(z)): -0.145/0.046\n",
      "[2/200][801/843] Loss_D: 0.021 Loss_G: 1.056 D(x): 1.005 D(G(z)): 0.068/-0.021\n",
      "epoch 2 D_loss is [0.07566195450643627, 0.03522974740568005]\n",
      "epoch 2 G_loss is [1.118073632001594, 1.0552752620384787]\n",
      "[3/200][1/843] Loss_D: 0.008 Loss_G: 0.986 D(x): 0.969 D(G(z)): 0.001/0.011\n",
      "[3/200][101/843] Loss_D: 0.016 Loss_G: 1.065 D(x): 1.006 D(G(z)): 0.042/-0.029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1b65dbdd9443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0merrD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrD_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merrD_fake\u001b[0m    \u001b[1;31m# 識別器Dの全体の損失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mD_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0merrD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0merrD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# 誤差逆伝播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moptimizerD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Dのパラメーターを更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "for epoch in range(n_epoch):\n",
    "    D_loss_sum = 0\n",
    "    G_loss_sum = 0\n",
    "    D_sum = []\n",
    "    G_sum = []\n",
    "    for itr, data in enumerate(dataloaders['train']):\n",
    "        real_image = data[0].to(device)     # 元配列\n",
    "        #print(real_image)\n",
    "        sample_size = real_image.size(0)    # 配列数\n",
    "        noise = torch.randn(sample_size, nz, 1, device=device)   # 正規分布からノイズを生成\n",
    "        \n",
    "        real_target = torch.full((sample_size,), 1., device=device)     # 元配列に対する識別信号の目標値「1」\n",
    "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作配列に対する識別信号の目標値「0」\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        netD.zero_grad()    # 勾配の初期化\n",
    "\n",
    "        output = netD(real_image)   # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_real = criterion(output, real_target)  # 元配列に対する識別信号の損失値\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = netG(noise)    # 生成器Gでノイズから贋作配列を生成\n",
    "        #print(fake_image.detach())\n",
    "        output = netD(fake_image.detach())  # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_fake = criterion(output, fake_target)  # 贋作配列に対する識別信号の損失値\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
    "        D_loss_sum += errD\n",
    "        D_sum.append(errD.cpu().detach().numpy())\n",
    "        print(\"D_sum is\",D_sum)\n",
    "        errD.backward()    # 誤差逆伝播\n",
    "        optimizerD.step()   # Dのパラメーターを更新\n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        netG.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作配列に対する識別信号を出力\n",
    "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作配列を元配列と誤認させたいため目標値は「1」\n",
    "        G_loss_sum += errG\n",
    "        G_sum.append(errG.cpu().detach().numpy())\n",
    "        print(\"G_sum is\",G_sum)\n",
    "        errG.backward()     # 誤差逆伝播\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step()   # Gのパラメータを更新\n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloaders['train']),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0:     # 初回に元配列を保存する\n",
    "            sem.vec2seq_save(\"real_pos_seq\", real_image.cpu(), 1)\n",
    "\n",
    "        #print(\"[\",itr,\"] SUM_lossD:\",D_loss_sum)\n",
    "        #print(\"[\",itr,\"] SUM_lossG:\",G_loss_sum)\n",
    "    ############################\n",
    "    # Lossの保存\n",
    "    ############################\n",
    "    \n",
    "    D_loss.append(D_loss_sum.cpu().detach().numpy() / len(dataloaders['train'])) #1epochごとのDiscreminaterのLossの平均を格納\n",
    "    G_loss.append(G_loss_sum.cpu().detach().numpy() / len(dataloaders['train'])) #1epochごとのGeneratorのLossの平均を格納\n",
    "    print(\"epoch\",epoch+1,\"D_loss is\",D_loss)\n",
    "    print(\"epoch\",epoch+1,\"G_loss is\",G_loss)\n",
    "    #print(fake_image.detach())\n",
    "#     vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "#                       normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用の配列生成とその配列の保存\n",
    "    ############################\n",
    "    if (epoch + 1) % 1 == 0:   # 5エポックごとにfakeseqを保存する\n",
    "        filename = 'fake_pos_seq_epoch' + str(epoch + 1)\n",
    "        fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作配列を生成する\n",
    "        sem.vec2seq_save(filename, fake_image.cpu().detach(), batch_size)\n",
    "#         torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "#         torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jIOzZdu6zyw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSGAN_ver2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
