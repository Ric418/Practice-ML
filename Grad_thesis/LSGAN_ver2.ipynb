{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSGAN_ver2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"76DG_1bf64GT","colab_type":"code","outputId":"901d18fc-2089-4942-8535-d03b30a06363","executionInfo":{"status":"ok","timestamp":1547759165030,"user_tz":-540,"elapsed":1410,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"vkzAllIK66ms","colab_type":"code","outputId":"95793c99-a6ac-40f6-c1fb-67f75a880de1","executionInfo":{"status":"ok","timestamp":1547759165030,"user_tz":-540,"elapsed":1390,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd /content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis\n"],"name":"stdout"}]},{"metadata":{"id":"2L53fqQ67E7e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"628e1b19-9b90-4407-f618-095ca2ce7572","executionInfo":{"status":"ok","timestamp":1547759210592,"user_tz":-540,"elapsed":46937,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}}},"cell_type":"code","source":["!pip install torch\n","!pip install torchvision\n","!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install pillow\n","!pip install opencv-python"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.9)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.3.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"],"name":"stdout"}]},{"metadata":{"id":"fPE7EzB96zyT","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import random\n","import copy\n","import argparse\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchvision import models, transforms\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import torchvision.utils as vutils\n","from sklearn.model_selection import train_test_split\n","\n","from seq_net import weights_init, Generator, Discriminator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zO4Zlp_46zyY","colab_type":"code","outputId":"c23f7c24-a098-4efd-e492-f1feb39cbee9","executionInfo":{"status":"ok","timestamp":1547759212587,"user_tz":-540,"elapsed":48895,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# 設定\n","workers = 0\n","batch_size=64\n","nz = 100\n","nch_g = 128\n","nch_d = 128\n","n_epoch = 200\n","lr = 0.0002\n","beta1 = 0.5\n","outf = './Result/lsGAN'\n","display_interval = 100\n","\n","# 保存先ディレクトリを作成\n","try:\n","    os.makedirs(outf, exist_ok=True)\n","except OSError as error: \n","    print(error)\n","    pass\n","\n","# 乱数のシード（種）を固定\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f10d241b610>"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"6pS2Hwb06zyd","colab_type":"code","colab":{}},"cell_type":"code","source":["SEQ_LENGTH = 128\n","\n","def make_dataset(datadir):\n","    '''\n","    convert sequence to vector array\n","    1.init array all 0 (4*SEQ_LENGTH)\n","    2.convert sequences (all 0 array) to vector array.\n","    ex. ACCGAT =\n","    0 0 0 0 0 0    1 0 0 0 1 0\n","    0 0 0 0 0 0  → 0 1 1 0 0 0\n","    0 0 0 0 0 0    0 0 0 1 0 0\n","    0 0 0 0 0 0    0 0 0 0 0 1\n","    '''\n","    pos_seq = \"SRX356455.05_peak_seq_128.txt\"\n","    # id      chr     start   end     seq\n","    data = pd.read_csv(os.path.join(datadir, \"sequences\", pos_seq), sep=\"\\t\")\n","    sequences = [] \n","    classes = [] #positive or negative\n","    for index, row in data[[\"id\", \"seq\"]].iterrows():\n","        y = 1 #positive\n","        seq_vector = seq2vector(row[\"seq\"])\n","        if len(seq_vector) == 0:\n","            continue\n","        sequences.append(seq2vector(row[\"seq\"]))\n","        classes.append(np.array(y))\n","    return sequences, classes\n","\n","def seq2vector(seq):\n","    if type(seq) is not str: # Case on Null sequence\n","        return np.zeros((0,0))\n","    seq_array = np.zeros((4, SEQ_LENGTH)) #initiallize 4*SEQ_LENGTH array all 0\n","    flag = 0\n","    for i in range(SEQ_LENGTH):\n","        s = seq[i]\n","        if s == \"a\" or s == \"A\":\n","            seq_array[0, i] = 1\n","        elif s == \"c\" or s == \"C\":\n","            seq_array[1, i] = 1\n","        elif s == \"g\" or s == \"G\":\n","            seq_array[2, i] = 1\n","        elif s == \"t\" or s == \"T\":\n","            seq_array[3, i] = 1\n","        else:\n","            flag += 1\n","    if len(seq) == flag: # Case on N sequence\n","        return np.zeros((0,0))\n","    seq_array = seq_array.astype(np.float32)\n","    return seq_array"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q3F_XWIE6zyg","colab_type":"code","outputId":"be6f1ed4-58d5-4382-bf74-5df47583877c","executionInfo":{"status":"ok","timestamp":1547759243762,"user_tz":-540,"elapsed":80045,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["datadir = \"data\"\n","\n","class DatasetFolder(data.Dataset):\n","    def __init__(self, X, y):\n","        self.samples = X\n","        self.targets = y\n","        self.transforms = transforms.Compose([\n","            ToTensorOfTarget()\n","        ])\n","\n","    def __getitem__(self, index):\n","        sample = self.samples[index]\n","        sample = self.transforms(sample)\n","        target = self.targets[index]\n","        target = self.transforms(target)\n","        return sample, target\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","\n","class ToTensorOfTarget(object):\n","    def __call__(self, target):\n","        return torch.from_numpy(target)\n","\n","# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n","# training + valid が、機械学習の training data 相当。\n","X, y = make_dataset(datadir)\n","X_tmp, X_test, y_tmp, y_test = train_test_split(\n","    X, y, test_size = 0.20)\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_tmp, y_tmp, test_size = 0.25\n",")\n","\n","\n","sequence_datasets = {\n","    'train':DatasetFolder(X_train, y_train),\n","    'val':DatasetFolder(X_val, y_val),\n","    'test': DatasetFolder(X_test, y_test)\n","}\n","\n","dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'val', 'test']}\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('device:', device)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["device: cuda:0\n"],"name":"stdout"}]},{"metadata":{"id":"LEJXjMwVG_pO","colab_type":"code","colab":{}},"cell_type":"code","source":["# バッチサイズ分のデータを読み込む。\n","# training はデータをシャッフルし、読み込み始める配列をランダムにする。\n","# 他はシャッフルの必要なし。\n","batch_size=64\n","workers=0\n","dataloaders = {\n","    'train': torch.utils.data.DataLoader(\n","        sequence_datasets['train'],\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=workers),\n","    'val': torch.utils.data.DataLoader(\n","        sequence_datasets['val'],\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=workers),\n","    'test': torch.utils.data.DataLoader(\n","        sequence_datasets['test'],\n","        batch_size=batch_size,\n","        shuffle=False,\n","        num_workers=workers)\n","}\n","dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'val', 'test']}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"THWJ0sN36zyk","colab_type":"code","outputId":"d949d121-77fa-4106-c4a8-39a52414fa2f","executionInfo":{"status":"ok","timestamp":1547759249997,"user_tz":-540,"elapsed":86262,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":578}},"cell_type":"code","source":["# 生成器G。ランダムベクトルから贋作画像を生成する\n","netG = Generator(nz=nz, nch_g=nch_g).to(device)\n","netG.apply(weights_init)    # weights_init関数で初期化\n","print(netG)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Generator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): ConvTranspose1d(100, 2048, kernel_size=(4,), stride=(1,))\n","      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer1): Sequential(\n","      (0): ConvTranspose1d(2048, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer2): Sequential(\n","      (0): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer3): Sequential(\n","      (0): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer4): Sequential(\n","      (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer5): Sequential(\n","      (0): ConvTranspose1d(128, 4, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): Tanh()\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"zIsEJjBi6zyn","colab_type":"code","outputId":"15be38a4-b909-46fa-e9f0-f43285d3979b","executionInfo":{"status":"ok","timestamp":1547759250430,"user_tz":-540,"elapsed":86685,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"cell_type":"code","source":["# 識別器D。画像が、元画像か贋作画像かを識別する\n","netD = Discriminator(nch_d=nch_d).to(device)\n","netD.apply(weights_init)\n","print(netD)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Discriminator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): Conv1d(4, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer1): Sequential(\n","      (0): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer2): Sequential(\n","      (0): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer3): Sequential(\n","      (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer4): Sequential(\n","      (0): Conv1d(1024, 2048, kernel_size=(4,), stride=(2,), padding=(1,))\n","      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer5): Conv1d(2048, 1, kernel_size=(4,), stride=(1,))\n","  )\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"abf1PyD96zyq","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n","\n","# オプティマイザ−のセットアップ\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n","\n","fixed_noise = torch.randn(batch_size, nz, 1,  device=device)  # 確認用の固定したノイズ"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dbEMPfif6zyt","colab_type":"code","outputId":"86de345c-27ff-4713-bf12-91e13f2e0f1a","executionInfo":{"status":"error","timestamp":1547757532865,"user_tz":-540,"elapsed":1431,"user":{"displayName":"Takuma Kobayashi","photoUrl":"https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg","userId":"06358397516930507128"}},"colab":{"base_uri":"https://localhost:8080/","height":1972}},"cell_type":"code","source":["# 学習のループ\n","for epoch in range(n_epoch):\n","    for itr, data in enumerate(dataloaders['train']):\n","        real_image = data[0].to(device)     # 元画像\n","#         print(data)\n","        sample_size = real_image.size(0)    # 画像枚数\n","        noise = torch.randn(sample_size, nz, 1, device=device)   # 正規分布からノイズを生成\n","        \n","        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n","        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n","        \n","        ############################\n","        # 識別器Dの更新\n","        ###########################\n","        netD.zero_grad()    # 勾配の初期化\n","\n","        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n","        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n","        D_x = output.mean().item()\n","\n","        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n","        #print(fake_image.detach())\n","        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n","        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n","        D_G_z1 = output.mean().item()\n","\n","        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n","        errD.backward()    # 誤差逆伝播\n","        optimizerD.step()   # Dのパラメーターを更新\n","\n","        ############################\n","        # 生成器Gの更新\n","        ###########################\n","        netG.zero_grad()    # 勾配の初期化\n","        \n","        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n","        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n","        errG.backward()     # 誤差逆伝播\n","        D_G_z2 = output.mean().item()\n","\n","        optimizerG.step()   # Gのパラメータを更新\n","\n","        if itr % display_interval == 0: \n","            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n","                  .format(epoch + 1, n_epoch,\n","                          itr + 1, len(dataloaders['train']),\n","                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","            \n","#         if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n","#             vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n","#                               normalize=True, nrow=10)\n","\n","    ############################\n","    # 確認用画像の生成\n","    ############################\n","    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n","    print(fake_image.detach())\n","#     vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n","#                       normalize=True, nrow=10)\n","\n","    ############################\n","    # モデルの保存\n","    ############################\n","    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n","        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n","        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1/200][1/511] Loss_D: 0.024 Loss_G: 0.899 D(x): 0.960 D(G(z)): 0.047/0.055\n","[1/200][101/511] Loss_D: 0.029 Loss_G: 0.837 D(x): 0.929 D(G(z)): 0.007/0.088\n","[1/200][201/511] Loss_D: 0.115 Loss_G: 1.408 D(x): 1.131 D(G(z)): 0.236/-0.178\n","[1/200][301/511] Loss_D: 0.702 Loss_G: 3.498 D(x): 1.482 D(G(z)): 0.648/-0.859\n","[1/200][401/511] Loss_D: 0.447 Loss_G: 0.226 D(x): 0.704 D(G(z)): -0.563/0.560\n","[1/200][501/511] Loss_D: 0.045 Loss_G: 1.270 D(x): 1.059 D(G(z)): 0.085/-0.120\n","tensor([[[-0.1235, -0.3272, -0.3778,  ...,  0.8450, -0.3810,  0.0600],\n","         [ 0.1158, -0.1856,  0.1661,  ...,  0.1024,  0.1572,  0.2405],\n","         [ 0.2385,  0.2921, -0.2283,  ..., -0.1200,  0.3574,  0.0238],\n","         [ 0.6330,  0.8174,  0.4777,  ...,  0.0763,  0.3628,  0.1042]],\n","\n","        [[-0.1241, -0.3161, -0.3253,  ...,  0.8451, -0.4919,  0.0327],\n","         [ 0.1180, -0.2057,  0.1503,  ...,  0.1053,  0.1631,  0.3091],\n","         [ 0.2255,  0.2965, -0.2613,  ..., -0.1724,  0.4435,  0.0288],\n","         [ 0.6065,  0.8163,  0.4573,  ...,  0.1523,  0.3905,  0.0652]],\n","\n","        [[-0.1725, -0.2912, -0.3692,  ...,  0.8229, -0.5108,  0.0295],\n","         [ 0.1083, -0.1818,  0.2711,  ...,  0.2125,  0.1212,  0.2897],\n","         [ 0.2528,  0.3671, -0.2503,  ..., -0.1309,  0.5267,  0.0474],\n","         [ 0.6340,  0.7599,  0.4947,  ...,  0.1061,  0.2781,  0.0799]],\n","\n","        ...,\n","\n","        [[-0.1969, -0.3165, -0.4231,  ...,  0.8210, -0.3937,  0.0531],\n","         [ 0.1196, -0.1933,  0.2400,  ...,  0.1450,  0.1557,  0.2554],\n","         [ 0.2548,  0.3280, -0.2180,  ..., -0.0652,  0.4843,  0.0361],\n","         [ 0.6533,  0.7754,  0.5065,  ...,  0.1306,  0.3257,  0.1369]],\n","\n","        [[-0.1695, -0.3406, -0.3979,  ...,  0.8536, -0.4295,  0.0076],\n","         [ 0.0904, -0.1744,  0.2916,  ...,  0.1047,  0.1020,  0.2749],\n","         [ 0.2562,  0.3687, -0.3043,  ..., -0.2412,  0.4403,  0.0650],\n","         [ 0.6487,  0.7377,  0.5264,  ...,  0.1175,  0.4128,  0.0321]],\n","\n","        [[-0.2216, -0.3354, -0.4299,  ...,  0.8212, -0.5140,  0.0574],\n","         [ 0.1330, -0.1494,  0.2889,  ...,  0.2115,  0.2127,  0.2956],\n","         [ 0.2490,  0.3544, -0.2629,  ..., -0.1266,  0.4100,  0.0237],\n","         [ 0.6538,  0.7583,  0.5228,  ...,  0.1269,  0.3889,  0.0568]]],\n","       device='cuda:0')\n","[2/200][1/511] Loss_D: 0.074 Loss_G: 0.660 D(x): 0.899 D(G(z)): -0.148/0.194\n","[2/200][101/511] Loss_D: 0.049 Loss_G: 0.761 D(x): 0.885 D(G(z)): -0.103/0.131\n","[2/200][201/511] Loss_D: 0.132 Loss_G: 1.796 D(x): 1.166 D(G(z)): 0.284/-0.337\n","[2/200][301/511] Loss_D: 0.798 Loss_G: 0.041 D(x): 0.552 D(G(z)): -0.737/0.944\n","[2/200][401/511] Loss_D: 0.222 Loss_G: 2.030 D(x): 1.223 D(G(z)): 0.379/-0.419\n","[2/200][501/511] Loss_D: 0.311 Loss_G: 1.851 D(x): 1.260 D(G(z)): 0.463/-0.357\n","tensor([[[ 0.6769, -0.5203,  0.3978,  ...,  0.4585,  0.7804,  0.0441],\n","         [-0.4203, -0.1738,  0.1703,  ...,  0.2396,  0.6564, -0.1251],\n","         [ 0.1140,  0.1072,  0.7484,  ...,  0.5552, -0.3879,  0.5126],\n","         [ 0.2793,  0.5152, -0.1321,  ..., -0.3343, -0.5129,  0.3816]],\n","\n","        [[ 0.6695, -0.4823,  0.4113,  ...,  0.3644,  0.6512,  0.0391],\n","         [-0.4045, -0.1583,  0.1505,  ...,  0.2646,  0.7108, -0.0537],\n","         [ 0.0913,  0.0426,  0.6957,  ...,  0.6402, -0.3124,  0.4982],\n","         [ 0.2782,  0.5675, -0.0985,  ..., -0.2087, -0.5637,  0.3554]],\n","\n","        [[ 0.6554, -0.5626,  0.2780,  ...,  0.3033,  0.6205,  0.0320],\n","         [-0.3727, -0.1590,  0.2633,  ...,  0.2632,  0.7176, -0.0691],\n","         [ 0.1242,  0.2100,  0.7695,  ...,  0.7041, -0.1146,  0.4892],\n","         [ 0.3244,  0.4005, -0.2057,  ..., -0.2554, -0.5632,  0.3481]],\n","\n","        ...,\n","\n","        [[ 0.6300, -0.6137,  0.3550,  ...,  0.4215,  0.7476,  0.0624],\n","         [-0.3788, -0.1565,  0.1971,  ...,  0.2300,  0.6769, -0.0899],\n","         [ 0.1600,  0.2157,  0.7587,  ...,  0.5938, -0.2811,  0.4981],\n","         [ 0.3165,  0.4641, -0.2603,  ..., -0.2756, -0.5411,  0.4035]],\n","\n","        [[ 0.6434, -0.6567,  0.2609,  ...,  0.3972,  0.6444,  0.0169],\n","         [-0.3959, -0.0837,  0.2960,  ...,  0.2277,  0.7014, -0.0596],\n","         [ 0.1386,  0.3111,  0.7156,  ...,  0.5999, -0.2991,  0.5083],\n","         [ 0.3366,  0.3941, -0.2062,  ..., -0.2076, -0.4905,  0.3357]],\n","\n","        [[ 0.6333, -0.6608,  0.2011,  ...,  0.2776,  0.6558,  0.0650],\n","         [-0.3741, -0.1104,  0.2944,  ...,  0.3075,  0.7282, -0.0461],\n","         [ 0.1422,  0.3355,  0.7903,  ...,  0.6602, -0.2293,  0.4967],\n","         [ 0.3271,  0.3969, -0.2897,  ..., -0.1894, -0.5746,  0.3333]]],\n","       device='cuda:0')\n","[3/200][1/511] Loss_D: 0.036 Loss_G: 1.050 D(x): 1.005 D(G(z)): -0.021/-0.018\n","[3/200][101/511] Loss_D: 0.100 Loss_G: 0.520 D(x): 0.850 D(G(z)): -0.225/0.291\n","[3/200][201/511] Loss_D: 0.051 Loss_G: 1.206 D(x): 0.988 D(G(z)): 0.149/-0.092\n","[3/200][301/511] Loss_D: 0.063 Loss_G: 0.785 D(x): 0.913 D(G(z)): -0.118/0.125\n","[3/200][401/511] Loss_D: 0.032 Loss_G: 1.061 D(x): 0.985 D(G(z)): 0.050/-0.025\n","[3/200][501/511] Loss_D: 0.140 Loss_G: 0.458 D(x): 0.781 D(G(z)): -0.249/0.340\n","tensor([[[-0.4497,  0.8262,  0.3904,  ...,  0.3165, -0.1554,  0.1198],\n","         [ 0.4784,  0.1726, -0.2073,  ..., -0.0853, -0.1773,  0.0910],\n","         [ 0.4258, -0.5478, -0.1079,  ...,  0.2206,  0.3980,  0.0787],\n","         [ 0.1107,  0.6692,  0.3353,  ...,  0.4018, -0.0265,  0.0546]],\n","\n","        [[-0.4419,  0.8198,  0.3005,  ...,  0.3682, -0.2042,  0.0757],\n","         [ 0.4406,  0.1049, -0.2611,  ..., -0.0221, -0.1701,  0.1426],\n","         [ 0.4146, -0.5462, -0.0854,  ...,  0.0903,  0.5438,  0.1082],\n","         [ 0.1012,  0.6224,  0.4219,  ...,  0.4359,  0.0914,  0.0157]],\n","\n","        [[-0.5179,  0.7929,  0.2500,  ...,  0.4302, -0.2207,  0.0434],\n","         [ 0.5199,  0.2062, -0.1986,  ...,  0.0171, -0.1090,  0.1267],\n","         [ 0.4036, -0.5451, -0.0344,  ...,  0.1107,  0.6015,  0.1178],\n","         [ 0.1477,  0.6003,  0.3440,  ...,  0.3802,  0.1797,  0.0086]],\n","\n","        ...,\n","\n","        [[-0.5272,  0.7640,  0.2664,  ...,  0.4038, -0.1704,  0.0953],\n","         [ 0.5238,  0.1878, -0.2414,  ..., -0.0512, -0.2083,  0.1031],\n","         [ 0.4326, -0.4945, -0.0172,  ...,  0.1679,  0.5313,  0.1237],\n","         [ 0.1285,  0.6062,  0.2920,  ...,  0.4308,  0.0901,  0.0462]],\n","\n","        [[-0.5210,  0.7415,  0.1546,  ...,  0.3589, -0.2313,  0.0604],\n","         [ 0.5251,  0.1805, -0.1447,  ..., -0.0408, -0.1502,  0.1292],\n","         [ 0.4083, -0.4600, -0.0119,  ...,  0.0543,  0.5775,  0.0901],\n","         [ 0.1097,  0.5362,  0.3948,  ...,  0.4250,  0.1044,  0.0315]],\n","\n","        [[-0.5831,  0.6838,  0.1136,  ...,  0.3503, -0.1977,  0.0935],\n","         [ 0.5485,  0.2957, -0.1550,  ...,  0.0175, -0.1871,  0.1475],\n","         [ 0.4024, -0.4605,  0.0781,  ...,  0.1339,  0.5574,  0.0752],\n","         [ 0.1186,  0.5284,  0.2867,  ...,  0.3996,  0.1130, -0.0029]]],\n","       device='cuda:0')\n","[4/200][1/511] Loss_D: 0.033 Loss_G: 1.018 D(x): 0.959 D(G(z)): 0.030/-0.005\n"],"name":"stdout"}]},{"metadata":{"id":"0jIOzZdu6zyw","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}