{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "76DG_1bf64GT",
    "outputId": "901d18fc-2089-4942-8535-d03b30a06363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "vkzAllIK66ms",
    "outputId": "95793c99-a6ac-40f6-c1fb-67f75a880de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46937,
     "status": "ok",
     "timestamp": 1547759210592,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "2L53fqQ67E7e",
    "outputId": "628e1b19-9b90-4407-f618-095ca2ce7572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPE7EzB96zyT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "from statistics import mean, variance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models, transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seq_net_ver2 import weights_init, Generator, Discriminator\n",
    "import seq_modules as sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48895,
     "status": "ok",
     "timestamp": 1547759212587,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zO4Zlp_46zyY",
    "outputId": "c23f7c24-a098-4efd-e492-f1feb39cbee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26fb79a6450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定\n",
    "workers = 0\n",
    "batch_size=32\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 50\n",
    "lr = 0.00002\n",
    "beta1 = 0.5\n",
    "outf = './Result/lsGAN'\n",
    "display_interval = 100\n",
    "\n",
    "# 保存先ディレクトリを作成\n",
    "try:\n",
    "    os.makedirs(outf, exist_ok=True)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "# 乱数のシード（種）を固定\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pS2Hwb06zyd"
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 128\n",
    "\n",
    "def make_dataset(datadir):\n",
    "    '''\n",
    "    convert sequence to vector array\n",
    "    1.init array all 0 (4*SEQ_LENGTH)\n",
    "    2.convert sequences (all 0 array) to vector array.\n",
    "    ex. ACCGAT =\n",
    "    0 0 0 0 0 0    1 0 0 0 1 0\n",
    "    0 0 0 0 0 0  → 0 1 1 0 0 0\n",
    "    0 0 0 0 0 0    0 0 0 1 0 0\n",
    "    0 0 0 0 0 0    0 0 0 0 0 1\n",
    "    '''\n",
    "    pos_seq = \"SRX356455.05_peak_seq_128.txt\"\n",
    "    # id      chr     start   end     seq\n",
    "    data = pd.read_csv(os.path.join(datadir, \"sequences\", pos_seq), sep=\"\\t\")\n",
    "    sequences = [] \n",
    "    classes = [] #positive or negative\n",
    "    for index, row in data[[\"id\", \"seq\"]].iterrows():\n",
    "        y = 1 #positive\n",
    "        seq_vector = seq2vector(row[\"seq\"])\n",
    "        if len(seq_vector) == 0:\n",
    "            continue\n",
    "        sequences.append(seq2vector(row[\"seq\"]))\n",
    "        classes.append(np.array(y))\n",
    "    return sequences, classes\n",
    "\n",
    "def seq2vector(seq):\n",
    "    if type(seq) is not str: # Case on Null sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = np.zeros((4, SEQ_LENGTH)) #initiallize 4*SEQ_LENGTH array all 0\n",
    "    flag = 0\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        s = seq[i]\n",
    "        if s == \"a\" or s == \"A\":\n",
    "            seq_array[0, i] = 1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"c\" or s == \"C\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = 1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"g\" or s == \"G\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = 1\n",
    "            seq_array[3, i] = -1\n",
    "        elif s == \"t\" or s == \"T\":\n",
    "            seq_array[0, i] = -1\n",
    "            seq_array[1, i] = -1\n",
    "            seq_array[2, i] = -1\n",
    "            seq_array[3, i] = 1\n",
    "        else:\n",
    "            flag += 1\n",
    "    if len(seq) == flag: # Case on N sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = seq_array.astype(np.float32)\n",
    "    return seq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80045,
     "status": "ok",
     "timestamp": 1547759243762,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "Q3F_XWIE6zyg",
    "outputId": "be6f1ed4-58d5-4382-bf74-5df47583877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "datadir = \"data\"\n",
    "\n",
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transforms = transforms.Compose([\n",
    "            ToTensorOfTarget()\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        sample = self.transforms(sample)\n",
    "        target = self.targets[index]\n",
    "        target = self.transforms(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data 相当。\n",
    "X, y = make_dataset(datadir)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.01)\n",
    "\n",
    "\n",
    "sequence_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train),\n",
    "    'test': DatasetFolder(X_test, y_test)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEJXjMwVG_pO"
   },
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める配列をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=32\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86262,
     "status": "ok",
     "timestamp": 1547759249997,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "THWJ0sN36zyk",
    "outputId": "d949d121-77fa-4106-c4a8-39a52414fa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): ConvTranspose1d(100, 2048, kernel_size=(4,), stride=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ConvTranspose1d(2048, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "      (3): Dropout(p=0.5)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "      (3): Dropout(p=0.5)\n",
      "    )\n",
      "    (layer5): Sequential(\n",
      "      (0): ConvTranspose1d(128, 4, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 生成器G。ランダムベクトルから贋作配列を生成する\n",
    "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
    "netG.apply(weights_init)    # weights_init関数で初期化\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86685,
     "status": "ok",
     "timestamp": 1547759250430,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zIsEJjBi6zyn",
    "outputId": "15be38a4-b909-46fa-e9f0-f43285d3979b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): Conv1d(4, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Conv1d(1024, 2048, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (layer5): Conv1d(2048, 1, kernel_size=(4,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 識別器D。配列が、元配列か贋作配列かを識別する\n",
    "netD = Discriminator(nch_d=nch_d).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abf1PyD96zyq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
    "\n",
    "# オプティマイザ−のセットアップ\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1,  device=device)  # 確認用の固定したノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1431,
     "status": "error",
     "timestamp": 1547757532865,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "dbEMPfif6zyt",
    "outputId": "86de345c-27ff-4713-bf12-91e13f2e0f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50][1/1686] Loss_D: 2.925 Loss_G: 0.606 D(x): 0.252 D(G(z)): 0.276/0.487\n",
      "[1/50][101/1686] Loss_D: 1.255 Loss_G: 0.789 D(x): 0.848 D(G(z)): 0.356/0.108\n",
      "[1/50][201/1686] Loss_D: 1.048 Loss_G: 0.866 D(x): 0.974 D(G(z)): 0.222/0.249\n",
      "[1/50][301/1686] Loss_D: 0.919 Loss_G: 0.273 D(x): 0.769 D(G(z)): 0.477/0.333\n",
      "[1/50][401/1686] Loss_D: 0.638 Loss_G: 0.421 D(x): 0.845 D(G(z)): 0.327/0.359\n",
      "[1/50][501/1686] Loss_D: 0.845 Loss_G: 0.638 D(x): 0.704 D(G(z)): 0.320/0.458\n",
      "[1/50][601/1686] Loss_D: 0.723 Loss_G: 0.566 D(x): 0.599 D(G(z)): 0.182/0.301\n",
      "[1/50][701/1686] Loss_D: 0.676 Loss_G: 0.555 D(x): 0.891 D(G(z)): 0.323/0.127\n",
      "[1/50][801/1686] Loss_D: 0.498 Loss_G: 0.456 D(x): 0.776 D(G(z)): 0.289/0.080\n",
      "[1/50][901/1686] Loss_D: 0.594 Loss_G: 0.527 D(x): 0.789 D(G(z)): 0.386/0.266\n",
      "[1/50][1001/1686] Loss_D: 0.407 Loss_G: 0.363 D(x): 0.768 D(G(z)): 0.094/0.232\n",
      "[1/50][1101/1686] Loss_D: 0.530 Loss_G: 1.026 D(x): 0.966 D(G(z)): 0.234/0.201\n",
      "[1/50][1201/1686] Loss_D: 0.354 Loss_G: 0.415 D(x): 0.972 D(G(z)): 0.351/0.225\n",
      "[1/50][1301/1686] Loss_D: 0.487 Loss_G: 0.378 D(x): 0.871 D(G(z)): 0.373/0.173\n",
      "[1/50][1401/1686] Loss_D: 0.382 Loss_G: 0.325 D(x): 0.842 D(G(z)): 0.359/0.243\n",
      "[1/50][1501/1686] Loss_D: 0.585 Loss_G: 0.312 D(x): 0.378 D(G(z)): 0.041/0.255\n",
      "[1/50][1601/1686] Loss_D: 0.549 Loss_G: 0.632 D(x): 0.647 D(G(z)): 0.299/0.274\n",
      "[2/50][1/1686] Loss_D: 0.614 Loss_G: 0.983 D(x): 0.817 D(G(z)): 0.060/0.183\n",
      "[2/50][101/1686] Loss_D: 0.497 Loss_G: 0.925 D(x): 0.805 D(G(z)): 0.112/0.242\n",
      "[2/50][201/1686] Loss_D: 0.335 Loss_G: 0.631 D(x): 0.931 D(G(z)): 0.202/0.294\n",
      "[2/50][301/1686] Loss_D: 0.362 Loss_G: 0.534 D(x): 0.877 D(G(z)): 0.269/0.491\n",
      "[2/50][401/1686] Loss_D: 0.458 Loss_G: 0.960 D(x): 0.977 D(G(z)): 0.152/0.067\n",
      "[2/50][501/1686] Loss_D: 0.347 Loss_G: 0.613 D(x): 0.965 D(G(z)): 0.130/0.082\n",
      "[2/50][601/1686] Loss_D: 0.326 Loss_G: 0.797 D(x): 0.792 D(G(z)): 0.106/0.148\n",
      "[2/50][701/1686] Loss_D: 0.299 Loss_G: 0.557 D(x): 0.718 D(G(z)): 0.041/0.125\n",
      "[2/50][801/1686] Loss_D: 0.496 Loss_G: 1.019 D(x): 0.699 D(G(z)): 0.032/0.112\n",
      "[2/50][901/1686] Loss_D: 0.318 Loss_G: 0.564 D(x): 0.932 D(G(z)): 0.259/0.201\n",
      "[2/50][1001/1686] Loss_D: 0.367 Loss_G: 0.598 D(x): 0.875 D(G(z)): 0.183/0.262\n",
      "[2/50][1101/1686] Loss_D: 0.488 Loss_G: 0.712 D(x): 0.555 D(G(z)): 0.073/0.204\n",
      "[2/50][1201/1686] Loss_D: 0.455 Loss_G: 0.706 D(x): 0.732 D(G(z)): -0.153/0.217\n",
      "[2/50][1301/1686] Loss_D: 0.316 Loss_G: 0.531 D(x): 0.799 D(G(z)): 0.073/0.034\n",
      "[2/50][1401/1686] Loss_D: 0.441 Loss_G: 0.726 D(x): 0.738 D(G(z)): 0.268/0.164\n",
      "[2/50][1501/1686] Loss_D: 0.331 Loss_G: 0.591 D(x): 0.687 D(G(z)): 0.054/0.183\n",
      "[2/50][1601/1686] Loss_D: 0.381 Loss_G: 1.070 D(x): 1.135 D(G(z)): 0.367/0.146\n",
      "[3/50][1/1686] Loss_D: 0.274 Loss_G: 0.878 D(x): 0.929 D(G(z)): 0.103/0.054\n",
      "[3/50][101/1686] Loss_D: 0.351 Loss_G: 0.708 D(x): 0.912 D(G(z)): 0.460/0.307\n",
      "[3/50][201/1686] Loss_D: 0.285 Loss_G: 0.802 D(x): 0.914 D(G(z)): 0.218/-0.079\n",
      "[3/50][301/1686] Loss_D: 0.531 Loss_G: 0.915 D(x): 0.697 D(G(z)): 0.182/0.194\n",
      "[3/50][401/1686] Loss_D: 0.208 Loss_G: 0.566 D(x): 0.951 D(G(z)): 0.305/0.244\n",
      "[3/50][501/1686] Loss_D: 0.205 Loss_G: 0.929 D(x): 0.867 D(G(z)): -0.010/-0.032\n",
      "[3/50][601/1686] Loss_D: 0.222 Loss_G: 0.461 D(x): 0.915 D(G(z)): 0.147/0.398\n",
      "[3/50][701/1686] Loss_D: 0.242 Loss_G: 0.470 D(x): 0.879 D(G(z)): 0.312/0.117\n",
      "[3/50][801/1686] Loss_D: 0.313 Loss_G: 0.767 D(x): 1.092 D(G(z)): 0.358/0.075\n",
      "[3/50][901/1686] Loss_D: 0.334 Loss_G: 0.439 D(x): 0.635 D(G(z)): -0.072/0.170\n",
      "[3/50][1001/1686] Loss_D: 0.297 Loss_G: 0.766 D(x): 0.922 D(G(z)): 0.256/0.218\n",
      "[3/50][1101/1686] Loss_D: 0.212 Loss_G: 0.373 D(x): 0.900 D(G(z)): 0.153/0.131\n",
      "[3/50][1201/1686] Loss_D: 0.254 Loss_G: 0.728 D(x): 1.073 D(G(z)): 0.421/0.282\n",
      "[3/50][1301/1686] Loss_D: 0.311 Loss_G: 0.678 D(x): 1.028 D(G(z)): 0.232/0.343\n",
      "[3/50][1401/1686] Loss_D: 0.170 Loss_G: 0.602 D(x): 0.895 D(G(z)): 0.118/0.214\n",
      "[3/50][1501/1686] Loss_D: 0.217 Loss_G: 0.472 D(x): 0.908 D(G(z)): 0.197/0.339\n",
      "[3/50][1601/1686] Loss_D: 0.364 Loss_G: 0.586 D(x): 1.149 D(G(z)): 0.348/0.068\n",
      "[4/50][1/1686] Loss_D: 0.203 Loss_G: 0.796 D(x): 0.903 D(G(z)): 0.049/-0.129\n",
      "[4/50][101/1686] Loss_D: 0.233 Loss_G: 0.604 D(x): 0.994 D(G(z)): 0.387/0.404\n",
      "[4/50][201/1686] Loss_D: 0.206 Loss_G: 1.212 D(x): 0.933 D(G(z)): 0.232/0.009\n",
      "[4/50][301/1686] Loss_D: 0.274 Loss_G: 0.767 D(x): 0.993 D(G(z)): 0.349/-0.017\n",
      "[4/50][401/1686] Loss_D: 0.179 Loss_G: 0.936 D(x): 1.056 D(G(z)): 0.285/0.198\n",
      "[4/50][501/1686] Loss_D: 0.229 Loss_G: 0.763 D(x): 0.794 D(G(z)): -0.112/0.110\n",
      "[4/50][601/1686] Loss_D: 0.242 Loss_G: 1.142 D(x): 0.867 D(G(z)): 0.060/0.121\n",
      "[4/50][701/1686] Loss_D: 0.171 Loss_G: 0.617 D(x): 0.911 D(G(z)): 0.248/0.022\n",
      "[4/50][801/1686] Loss_D: 0.186 Loss_G: 0.983 D(x): 0.875 D(G(z)): 0.235/0.083\n",
      "[4/50][901/1686] Loss_D: 0.146 Loss_G: 0.400 D(x): 0.996 D(G(z)): 0.253/0.224\n",
      "[4/50][1001/1686] Loss_D: 0.173 Loss_G: 0.565 D(x): 0.934 D(G(z)): 0.173/-0.002\n",
      "[4/50][1101/1686] Loss_D: 0.184 Loss_G: 0.897 D(x): 1.040 D(G(z)): 0.326/0.249\n",
      "[4/50][1201/1686] Loss_D: 0.145 Loss_G: 0.646 D(x): 0.924 D(G(z)): 0.100/0.206\n",
      "[4/50][1301/1686] Loss_D: 0.132 Loss_G: 0.863 D(x): 1.000 D(G(z)): 0.202/0.242\n",
      "[4/50][1401/1686] Loss_D: 0.199 Loss_G: 0.762 D(x): 0.990 D(G(z)): 0.210/0.060\n",
      "[4/50][1501/1686] Loss_D: 0.103 Loss_G: 0.816 D(x): 0.914 D(G(z)): 0.159/0.107\n",
      "[4/50][1601/1686] Loss_D: 0.103 Loss_G: 0.696 D(x): 0.918 D(G(z)): 0.280/0.233\n",
      "[5/50][1/1686] Loss_D: 0.322 Loss_G: 0.749 D(x): 0.779 D(G(z)): 0.103/-0.105\n",
      "[5/50][101/1686] Loss_D: 0.156 Loss_G: 0.708 D(x): 0.919 D(G(z)): 0.174/-0.104\n",
      "[5/50][201/1686] Loss_D: 0.100 Loss_G: 0.825 D(x): 0.933 D(G(z)): 0.186/0.148\n",
      "[5/50][301/1686] Loss_D: 0.152 Loss_G: 0.548 D(x): 0.929 D(G(z)): 0.005/0.217\n",
      "[5/50][401/1686] Loss_D: 0.072 Loss_G: 0.523 D(x): 0.976 D(G(z)): 0.254/0.331\n",
      "[5/50][501/1686] Loss_D: 0.066 Loss_G: 0.716 D(x): 0.998 D(G(z)): 0.183/0.249\n",
      "[5/50][601/1686] Loss_D: 0.110 Loss_G: 0.470 D(x): 0.790 D(G(z)): 0.086/0.222\n",
      "[5/50][701/1686] Loss_D: 0.149 Loss_G: 0.737 D(x): 1.158 D(G(z)): 0.473/0.349\n",
      "[5/50][801/1686] Loss_D: 0.118 Loss_G: 1.227 D(x): 0.930 D(G(z)): 0.064/0.086\n",
      "[5/50][901/1686] Loss_D: 0.147 Loss_G: 0.650 D(x): 1.194 D(G(z)): 0.361/0.102\n",
      "[5/50][1001/1686] Loss_D: 0.162 Loss_G: 1.101 D(x): 0.770 D(G(z)): 0.103/0.054\n",
      "[5/50][1101/1686] Loss_D: 0.075 Loss_G: 0.343 D(x): 0.937 D(G(z)): 0.216/0.299\n",
      "[5/50][1201/1686] Loss_D: 0.081 Loss_G: 0.834 D(x): 0.982 D(G(z)): 0.121/0.123\n",
      "[5/50][1301/1686] Loss_D: 0.071 Loss_G: 0.718 D(x): 0.916 D(G(z)): 0.182/0.017\n",
      "[5/50][1401/1686] Loss_D: 0.101 Loss_G: 0.998 D(x): 0.825 D(G(z)): 0.092/0.059\n",
      "[5/50][1501/1686] Loss_D: 0.077 Loss_G: 0.773 D(x): 0.842 D(G(z)): 0.063/0.119\n",
      "[5/50][1601/1686] Loss_D: 0.143 Loss_G: 1.106 D(x): 0.892 D(G(z)): 0.121/0.146\n",
      "[6/50][1/1686] Loss_D: 0.189 Loss_G: 0.528 D(x): 0.991 D(G(z)): 0.154/0.053\n",
      "[6/50][101/1686] Loss_D: 0.071 Loss_G: 0.521 D(x): 0.715 D(G(z)): 0.097/0.149\n",
      "[6/50][201/1686] Loss_D: 0.051 Loss_G: 0.454 D(x): 0.989 D(G(z)): 0.186/0.329\n",
      "[6/50][301/1686] Loss_D: 0.074 Loss_G: 0.574 D(x): 0.908 D(G(z)): 0.302/0.341\n",
      "[6/50][401/1686] Loss_D: 0.051 Loss_G: 0.524 D(x): 0.773 D(G(z)): 0.050/0.143\n",
      "[6/50][501/1686] Loss_D: 0.140 Loss_G: 0.625 D(x): 0.832 D(G(z)): 0.058/0.277\n",
      "[6/50][601/1686] Loss_D: 0.101 Loss_G: 0.418 D(x): 0.824 D(G(z)): 0.113/0.374\n",
      "[6/50][701/1686] Loss_D: 0.113 Loss_G: 0.535 D(x): 0.817 D(G(z)): 0.051/0.312\n",
      "[6/50][801/1686] Loss_D: 0.245 Loss_G: 0.220 D(x): 0.765 D(G(z)): -0.177/0.320\n",
      "[6/50][901/1686] Loss_D: 0.060 Loss_G: 0.975 D(x): 0.875 D(G(z)): 0.070/0.024\n",
      "[6/50][1001/1686] Loss_D: 0.143 Loss_G: 0.841 D(x): 0.961 D(G(z)): 0.035/0.271\n",
      "[6/50][1101/1686] Loss_D: 0.139 Loss_G: 0.441 D(x): 0.852 D(G(z)): -0.066/0.122\n",
      "[6/50][1201/1686] Loss_D: 0.040 Loss_G: 0.628 D(x): 0.972 D(G(z)): 0.273/0.211\n",
      "[6/50][1301/1686] Loss_D: 0.161 Loss_G: 0.498 D(x): 1.028 D(G(z)): 0.234/0.020\n",
      "[6/50][1401/1686] Loss_D: 0.049 Loss_G: 0.829 D(x): 1.117 D(G(z)): 0.330/0.182\n",
      "[6/50][1501/1686] Loss_D: 0.052 Loss_G: 0.253 D(x): 0.807 D(G(z)): 0.175/0.214\n",
      "[6/50][1601/1686] Loss_D: 0.137 Loss_G: 0.785 D(x): 0.836 D(G(z)): 0.016/0.246\n",
      "[7/50][1/1686] Loss_D: 0.073 Loss_G: 0.451 D(x): 0.934 D(G(z)): 0.138/0.100\n",
      "[7/50][101/1686] Loss_D: 0.232 Loss_G: 0.932 D(x): 0.757 D(G(z)): 0.019/0.233\n",
      "[7/50][201/1686] Loss_D: 0.181 Loss_G: 0.677 D(x): 0.983 D(G(z)): 0.303/-0.100\n",
      "[7/50][301/1686] Loss_D: 0.140 Loss_G: 0.401 D(x): 0.742 D(G(z)): 0.006/0.359\n",
      "[7/50][401/1686] Loss_D: 0.186 Loss_G: 0.606 D(x): 1.075 D(G(z)): 0.481/0.105\n",
      "[7/50][501/1686] Loss_D: 0.018 Loss_G: 0.548 D(x): 0.830 D(G(z)): 0.131/0.102\n",
      "[7/50][601/1686] Loss_D: 0.044 Loss_G: 0.697 D(x): 0.946 D(G(z)): 0.198/0.112\n",
      "[7/50][701/1686] Loss_D: 0.029 Loss_G: 0.523 D(x): 0.939 D(G(z)): 0.195/0.242\n",
      "[7/50][801/1686] Loss_D: 0.051 Loss_G: 0.702 D(x): 1.040 D(G(z)): 0.198/0.133\n",
      "[7/50][901/1686] Loss_D: 0.083 Loss_G: 0.664 D(x): 0.923 D(G(z)): 0.258/0.364\n",
      "[7/50][1001/1686] Loss_D: 0.139 Loss_G: 0.458 D(x): 1.006 D(G(z)): 0.362/0.144\n",
      "[7/50][1101/1686] Loss_D: 0.209 Loss_G: 0.515 D(x): 0.695 D(G(z)): -0.083/0.273\n",
      "[7/50][1201/1686] Loss_D: 0.024 Loss_G: 0.230 D(x): 0.855 D(G(z)): 0.233/0.272\n",
      "[7/50][1301/1686] Loss_D: 0.095 Loss_G: 0.357 D(x): 0.774 D(G(z)): 0.001/0.242\n",
      "[7/50][1401/1686] Loss_D: 0.071 Loss_G: 0.646 D(x): 0.940 D(G(z)): 0.244/0.011\n",
      "[7/50][1501/1686] Loss_D: 0.039 Loss_G: 0.813 D(x): 0.828 D(G(z)): 0.142/0.016\n",
      "[7/50][1601/1686] Loss_D: 0.039 Loss_G: 0.609 D(x): 0.872 D(G(z)): 0.048/-0.050\n",
      "[8/50][1/1686] Loss_D: 0.069 Loss_G: 0.738 D(x): 0.913 D(G(z)): 0.262/0.275\n",
      "[8/50][101/1686] Loss_D: 0.074 Loss_G: 0.949 D(x): 0.940 D(G(z)): 0.242/-0.004\n",
      "[8/50][201/1686] Loss_D: 0.040 Loss_G: 0.420 D(x): 0.891 D(G(z)): 0.189/0.306\n",
      "[8/50][301/1686] Loss_D: 0.014 Loss_G: 0.715 D(x): 0.821 D(G(z)): 0.040/-0.097\n",
      "[8/50][401/1686] Loss_D: 0.035 Loss_G: 0.762 D(x): 0.936 D(G(z)): 0.158/-0.045\n",
      "[8/50][501/1686] Loss_D: 0.036 Loss_G: 0.560 D(x): 0.792 D(G(z)): -0.000/0.075\n",
      "[8/50][601/1686] Loss_D: 0.030 Loss_G: 0.594 D(x): 0.978 D(G(z)): 0.086/0.186\n",
      "[8/50][701/1686] Loss_D: 0.065 Loss_G: 0.618 D(x): 1.002 D(G(z)): 0.279/0.102\n",
      "[8/50][801/1686] Loss_D: 0.041 Loss_G: 0.722 D(x): 0.930 D(G(z)): 0.053/0.214\n",
      "[8/50][901/1686] Loss_D: 0.026 Loss_G: 0.460 D(x): 0.911 D(G(z)): 0.166/0.273\n",
      "[8/50][1001/1686] Loss_D: 0.022 Loss_G: 0.483 D(x): 0.736 D(G(z)): 0.063/0.113\n",
      "[8/50][1101/1686] Loss_D: 0.062 Loss_G: 0.723 D(x): 0.879 D(G(z)): 0.190/0.178\n",
      "[8/50][1201/1686] Loss_D: 0.018 Loss_G: 1.104 D(x): 0.964 D(G(z)): 0.124/-0.064\n",
      "[8/50][1301/1686] Loss_D: 0.064 Loss_G: 0.886 D(x): 0.976 D(G(z)): 0.056/0.254\n",
      "[8/50][1401/1686] Loss_D: 0.034 Loss_G: 0.547 D(x): 0.913 D(G(z)): 0.210/0.090\n",
      "[8/50][1501/1686] Loss_D: 0.068 Loss_G: 0.875 D(x): 1.047 D(G(z)): 0.253/0.193\n",
      "[8/50][1601/1686] Loss_D: 0.093 Loss_G: 0.593 D(x): 0.795 D(G(z)): 0.231/0.279\n",
      "[9/50][1/1686] Loss_D: 0.028 Loss_G: 0.433 D(x): 0.930 D(G(z)): 0.268/0.231\n",
      "[9/50][101/1686] Loss_D: 0.028 Loss_G: 0.559 D(x): 1.090 D(G(z)): 0.381/0.326\n",
      "[9/50][201/1686] Loss_D: 0.119 Loss_G: 0.453 D(x): 0.961 D(G(z)): 0.356/0.178\n",
      "[9/50][301/1686] Loss_D: 0.030 Loss_G: 0.924 D(x): 0.905 D(G(z)): 0.042/0.071\n",
      "[9/50][401/1686] Loss_D: 0.047 Loss_G: 1.060 D(x): 1.040 D(G(z)): 0.185/0.129\n",
      "[9/50][501/1686] Loss_D: 0.082 Loss_G: 1.123 D(x): 0.912 D(G(z)): 0.097/0.122\n",
      "[9/50][601/1686] Loss_D: 0.027 Loss_G: 0.799 D(x): 0.891 D(G(z)): 0.155/0.078\n",
      "[9/50][701/1686] Loss_D: 0.064 Loss_G: 1.045 D(x): 0.858 D(G(z)): 0.014/0.046\n",
      "[9/50][801/1686] Loss_D: 0.047 Loss_G: 0.494 D(x): 0.969 D(G(z)): 0.179/0.124\n",
      "[9/50][901/1686] Loss_D: 0.020 Loss_G: 0.678 D(x): 0.900 D(G(z)): 0.121/0.022\n",
      "[9/50][1001/1686] Loss_D: 0.126 Loss_G: 1.272 D(x): 0.953 D(G(z)): 0.292/0.009\n",
      "[9/50][1101/1686] Loss_D: 0.074 Loss_G: 0.422 D(x): 0.853 D(G(z)): -0.042/0.187\n",
      "[9/50][1201/1686] Loss_D: 0.084 Loss_G: 0.881 D(x): 0.942 D(G(z)): 0.158/0.263\n",
      "[9/50][1301/1686] Loss_D: 0.013 Loss_G: 1.058 D(x): 1.064 D(G(z)): 0.099/0.109\n",
      "[9/50][1401/1686] Loss_D: 0.073 Loss_G: 0.828 D(x): 0.810 D(G(z)): 0.152/0.140\n",
      "[9/50][1501/1686] Loss_D: 0.062 Loss_G: 1.514 D(x): 0.992 D(G(z)): 0.042/-0.088\n",
      "[9/50][1601/1686] Loss_D: 0.058 Loss_G: 0.468 D(x): 0.981 D(G(z)): 0.309/0.134\n",
      "[10/50][1/1686] Loss_D: 0.027 Loss_G: 0.476 D(x): 0.904 D(G(z)): 0.194/0.131\n",
      "[10/50][101/1686] Loss_D: 0.067 Loss_G: 0.472 D(x): 0.911 D(G(z)): 0.054/0.165\n",
      "[10/50][201/1686] Loss_D: 0.090 Loss_G: 0.590 D(x): 0.798 D(G(z)): 0.252/0.308\n",
      "[10/50][301/1686] Loss_D: 0.012 Loss_G: 0.561 D(x): 0.939 D(G(z)): 0.167/0.151\n",
      "[10/50][401/1686] Loss_D: 0.010 Loss_G: 0.670 D(x): 0.836 D(G(z)): 0.085/-0.014\n",
      "[10/50][501/1686] Loss_D: 0.098 Loss_G: 0.961 D(x): 1.040 D(G(z)): 0.334/-0.100\n",
      "[10/50][601/1686] Loss_D: 0.026 Loss_G: 0.557 D(x): 0.927 D(G(z)): 0.071/0.120\n",
      "[10/50][701/1686] Loss_D: 0.037 Loss_G: 0.655 D(x): 1.092 D(G(z)): 0.112/0.318\n",
      "[10/50][801/1686] Loss_D: 0.141 Loss_G: 0.521 D(x): 0.754 D(G(z)): -0.119/-0.003\n",
      "[10/50][901/1686] Loss_D: 0.056 Loss_G: 0.788 D(x): 0.926 D(G(z)): 0.199/0.240\n",
      "[10/50][1001/1686] Loss_D: 0.059 Loss_G: 0.234 D(x): 0.941 D(G(z)): 0.194/0.244\n",
      "[10/50][1101/1686] Loss_D: 0.163 Loss_G: 0.341 D(x): 1.115 D(G(z)): 0.333/0.158\n",
      "[10/50][1201/1686] Loss_D: 0.015 Loss_G: 0.327 D(x): 0.935 D(G(z)): 0.291/0.342\n",
      "[10/50][1301/1686] Loss_D: 0.022 Loss_G: 0.760 D(x): 0.969 D(G(z)): 0.250/0.182\n",
      "[10/50][1401/1686] Loss_D: 0.020 Loss_G: 0.796 D(x): 0.993 D(G(z)): 0.194/0.134\n",
      "[10/50][1501/1686] Loss_D: 0.066 Loss_G: 0.568 D(x): 0.893 D(G(z)): 0.207/0.005\n",
      "[10/50][1601/1686] Loss_D: 0.118 Loss_G: 0.427 D(x): 1.051 D(G(z)): 0.178/0.073\n",
      "[11/50][1/1686] Loss_D: 0.036 Loss_G: 0.473 D(x): 0.807 D(G(z)): 0.115/0.049\n",
      "[11/50][101/1686] Loss_D: 0.015 Loss_G: 0.472 D(x): 0.907 D(G(z)): 0.220/0.177\n",
      "[11/50][201/1686] Loss_D: 0.059 Loss_G: 0.871 D(x): 0.920 D(G(z)): 0.230/0.057\n",
      "[11/50][301/1686] Loss_D: 0.162 Loss_G: 0.795 D(x): 1.087 D(G(z)): 0.228/-0.129\n",
      "[11/50][401/1686] Loss_D: 0.030 Loss_G: 0.455 D(x): 0.898 D(G(z)): 0.066/0.206\n",
      "[11/50][501/1686] Loss_D: 0.071 Loss_G: 0.686 D(x): 0.890 D(G(z)): 0.176/0.317\n",
      "[11/50][601/1686] Loss_D: 0.019 Loss_G: 0.511 D(x): 0.729 D(G(z)): 0.055/0.041\n",
      "[11/50][701/1686] Loss_D: 0.101 Loss_G: 0.746 D(x): 0.881 D(G(z)): 0.246/0.326\n",
      "[11/50][801/1686] Loss_D: 0.095 Loss_G: 1.028 D(x): 0.862 D(G(z)): 0.137/0.144\n",
      "[11/50][901/1686] Loss_D: 0.355 Loss_G: 1.128 D(x): 0.630 D(G(z)): -0.104/0.133\n",
      "[11/50][1001/1686] Loss_D: 0.020 Loss_G: 0.720 D(x): 0.991 D(G(z)): 0.189/0.184\n",
      "[11/50][1101/1686] Loss_D: 0.049 Loss_G: 0.721 D(x): 1.016 D(G(z)): 0.219/0.288\n",
      "[11/50][1201/1686] Loss_D: 0.124 Loss_G: 0.409 D(x): 0.878 D(G(z)): -0.050/0.211\n",
      "[11/50][1301/1686] Loss_D: 0.068 Loss_G: 0.620 D(x): 0.917 D(G(z)): -0.027/0.102\n",
      "[11/50][1401/1686] Loss_D: 0.038 Loss_G: 0.612 D(x): 0.958 D(G(z)): 0.042/0.039\n",
      "[11/50][1501/1686] Loss_D: 0.091 Loss_G: 1.032 D(x): 0.875 D(G(z)): 0.154/0.150\n",
      "[11/50][1601/1686] Loss_D: 0.019 Loss_G: 0.907 D(x): 1.054 D(G(z)): 0.052/0.034\n",
      "[12/50][1/1686] Loss_D: 0.104 Loss_G: 0.716 D(x): 0.904 D(G(z)): 0.219/0.356\n",
      "[12/50][101/1686] Loss_D: 0.049 Loss_G: 0.409 D(x): 0.802 D(G(z)): 0.086/0.257\n",
      "[12/50][201/1686] Loss_D: 0.124 Loss_G: 0.733 D(x): 0.864 D(G(z)): 0.053/0.264\n",
      "[12/50][301/1686] Loss_D: 0.032 Loss_G: 0.403 D(x): 0.988 D(G(z)): 0.187/0.207\n",
      "[12/50][401/1686] Loss_D: 0.034 Loss_G: 1.089 D(x): 1.041 D(G(z)): 0.106/0.153\n",
      "[12/50][501/1686] Loss_D: 0.095 Loss_G: 0.949 D(x): 0.953 D(G(z)): 0.188/0.211\n",
      "[12/50][601/1686] Loss_D: 0.053 Loss_G: 0.584 D(x): 0.933 D(G(z)): 0.290/0.218\n",
      "[12/50][701/1686] Loss_D: 0.015 Loss_G: 0.601 D(x): 0.892 D(G(z)): 0.153/0.163\n",
      "[12/50][801/1686] Loss_D: 0.061 Loss_G: 0.678 D(x): 0.948 D(G(z)): 0.211/0.339\n",
      "[12/50][901/1686] Loss_D: 0.053 Loss_G: 0.895 D(x): 0.750 D(G(z)): -0.060/-0.000\n",
      "[12/50][1001/1686] Loss_D: 0.016 Loss_G: 0.632 D(x): 0.901 D(G(z)): 0.124/0.170\n",
      "[12/50][1101/1686] Loss_D: 0.080 Loss_G: 0.488 D(x): 0.985 D(G(z)): 0.110/0.021\n",
      "[12/50][1201/1686] Loss_D: 0.012 Loss_G: 0.646 D(x): 0.924 D(G(z)): 0.172/0.153\n",
      "[12/50][1301/1686] Loss_D: 0.085 Loss_G: 0.752 D(x): 1.070 D(G(z)): 0.275/0.099\n",
      "[12/50][1401/1686] Loss_D: 0.006 Loss_G: 0.445 D(x): 1.038 D(G(z)): 0.292/0.337\n",
      "[12/50][1501/1686] Loss_D: 0.181 Loss_G: 1.035 D(x): 0.756 D(G(z)): -0.043/0.106\n",
      "[12/50][1601/1686] Loss_D: 0.038 Loss_G: 0.992 D(x): 1.076 D(G(z)): 0.222/0.169\n",
      "[13/50][1/1686] Loss_D: 0.084 Loss_G: 0.957 D(x): 0.842 D(G(z)): -0.003/0.128\n",
      "[13/50][101/1686] Loss_D: 0.052 Loss_G: 0.478 D(x): 1.017 D(G(z)): 0.303/0.194\n",
      "[13/50][201/1686] Loss_D: 0.048 Loss_G: 1.090 D(x): 0.854 D(G(z)): 0.031/0.009\n",
      "[13/50][301/1686] Loss_D: 0.022 Loss_G: 0.590 D(x): 0.973 D(G(z)): 0.093/0.191\n",
      "[13/50][401/1686] Loss_D: 0.034 Loss_G: 0.606 D(x): 1.075 D(G(z)): 0.160/0.206\n",
      "[13/50][501/1686] Loss_D: 0.074 Loss_G: 1.070 D(x): 0.883 D(G(z)): 0.136/0.101\n",
      "[13/50][601/1686] Loss_D: 0.032 Loss_G: 0.317 D(x): 0.780 D(G(z)): 0.083/0.212\n",
      "[13/50][701/1686] Loss_D: 0.022 Loss_G: 0.664 D(x): 1.104 D(G(z)): 0.196/0.186\n",
      "[13/50][801/1686] Loss_D: 0.066 Loss_G: 0.745 D(x): 1.061 D(G(z)): 0.281/0.076\n",
      "[13/50][901/1686] Loss_D: 0.030 Loss_G: 0.632 D(x): 0.951 D(G(z)): 0.316/0.272\n",
      "[13/50][1001/1686] Loss_D: 0.023 Loss_G: 1.244 D(x): 1.009 D(G(z)): 0.016/-0.033\n",
      "[13/50][1101/1686] Loss_D: 0.015 Loss_G: 0.462 D(x): 0.855 D(G(z)): 0.161/0.101\n",
      "[13/50][1201/1686] Loss_D: 0.054 Loss_G: 0.860 D(x): 0.975 D(G(z)): 0.240/0.226\n",
      "[13/50][1301/1686] Loss_D: 0.024 Loss_G: 0.959 D(x): 0.882 D(G(z)): 0.027/0.042\n",
      "[13/50][1401/1686] Loss_D: 0.024 Loss_G: 0.888 D(x): 1.029 D(G(z)): 0.141/0.006\n",
      "[13/50][1501/1686] Loss_D: 0.027 Loss_G: 0.627 D(x): 0.911 D(G(z)): 0.198/0.241\n",
      "[13/50][1601/1686] Loss_D: 0.015 Loss_G: 0.691 D(x): 0.900 D(G(z)): 0.118/0.023\n",
      "[14/50][1/1686] Loss_D: 0.047 Loss_G: 0.579 D(x): 0.923 D(G(z)): 0.208/0.318\n",
      "[14/50][101/1686] Loss_D: 0.087 Loss_G: 0.541 D(x): 0.861 D(G(z)): 0.164/0.383\n",
      "[14/50][201/1686] Loss_D: 0.040 Loss_G: 1.052 D(x): 0.990 D(G(z)): 0.179/0.061\n",
      "[14/50][301/1686] Loss_D: 0.090 Loss_G: 0.862 D(x): 0.864 D(G(z)): 0.116/0.224\n",
      "[14/50][401/1686] Loss_D: 0.018 Loss_G: 0.495 D(x): 0.858 D(G(z)): 0.138/0.068\n",
      "[14/50][501/1686] Loss_D: 0.011 Loss_G: 0.640 D(x): 0.917 D(G(z)): 0.218/0.176\n",
      "[14/50][601/1686] Loss_D: 0.043 Loss_G: 0.682 D(x): 0.878 D(G(z)): 0.115/0.236\n",
      "[14/50][701/1686] Loss_D: 0.019 Loss_G: 0.492 D(x): 1.094 D(G(z)): 0.285/0.315\n",
      "[14/50][801/1686] Loss_D: 0.009 Loss_G: 0.725 D(x): 1.073 D(G(z)): 0.173/0.203\n",
      "[14/50][901/1686] Loss_D: 0.018 Loss_G: 0.408 D(x): 0.937 D(G(z)): 0.138/0.185\n",
      "[14/50][1001/1686] Loss_D: 0.022 Loss_G: 0.603 D(x): 1.032 D(G(z)): 0.168/0.216\n",
      "[14/50][1101/1686] Loss_D: 0.018 Loss_G: 0.625 D(x): 0.940 D(G(z)): 0.066/0.047\n",
      "[14/50][1201/1686] Loss_D: 0.123 Loss_G: 0.646 D(x): 0.765 D(G(z)): -0.031/0.185\n",
      "[14/50][1301/1686] Loss_D: 0.046 Loss_G: 0.540 D(x): 0.929 D(G(z)): 0.104/0.256\n",
      "[14/50][1401/1686] Loss_D: 0.015 Loss_G: 0.621 D(x): 0.842 D(G(z)): 0.101/0.029\n",
      "[14/50][1501/1686] Loss_D: 0.036 Loss_G: 0.555 D(x): 0.886 D(G(z)): 0.044/0.090\n",
      "[14/50][1601/1686] Loss_D: 0.047 Loss_G: 0.800 D(x): 0.999 D(G(z)): 0.247/0.177\n",
      "[15/50][1/1686] Loss_D: 0.042 Loss_G: 0.383 D(x): 0.863 D(G(z)): 0.215/0.180\n",
      "[15/50][101/1686] Loss_D: 0.013 Loss_G: 0.731 D(x): 1.006 D(G(z)): 0.175/0.202\n",
      "[15/50][201/1686] Loss_D: 0.021 Loss_G: 0.564 D(x): 1.004 D(G(z)): 0.221/0.265\n",
      "[15/50][301/1686] Loss_D: 0.017 Loss_G: 0.731 D(x): 0.973 D(G(z)): 0.104/0.157\n",
      "[15/50][401/1686] Loss_D: 0.008 Loss_G: 0.405 D(x): 0.970 D(G(z)): 0.261/0.335\n",
      "[15/50][501/1686] Loss_D: 0.085 Loss_G: 0.386 D(x): 0.897 D(G(z)): 0.035/0.099\n",
      "[15/50][601/1686] Loss_D: 0.006 Loss_G: 0.358 D(x): 0.952 D(G(z)): 0.290/0.313\n",
      "[15/50][701/1686] Loss_D: 0.034 Loss_G: 0.515 D(x): 1.043 D(G(z)): 0.146/0.179\n",
      "[15/50][801/1686] Loss_D: 0.025 Loss_G: 0.545 D(x): 0.967 D(G(z)): 0.205/0.117\n",
      "[15/50][901/1686] Loss_D: 0.007 Loss_G: 0.474 D(x): 0.871 D(G(z)): 0.155/0.201\n",
      "[15/50][1001/1686] Loss_D: 0.022 Loss_G: 0.680 D(x): 0.879 D(G(z)): 0.080/0.020\n",
      "[15/50][1101/1686] Loss_D: 0.140 Loss_G: 0.397 D(x): 1.023 D(G(z)): 0.367/0.140\n",
      "[15/50][1201/1686] Loss_D: 0.089 Loss_G: 0.895 D(x): 0.802 D(G(z)): 0.012/0.134\n",
      "[15/50][1301/1686] Loss_D: 0.049 Loss_G: 0.551 D(x): 0.915 D(G(z)): 0.206/0.080\n",
      "[15/50][1401/1686] Loss_D: 0.026 Loss_G: 0.707 D(x): 0.858 D(G(z)): 0.145/0.045\n",
      "[15/50][1501/1686] Loss_D: 0.019 Loss_G: 0.648 D(x): 0.984 D(G(z)): 0.263/0.303\n",
      "[15/50][1601/1686] Loss_D: 0.028 Loss_G: 0.910 D(x): 0.843 D(G(z)): 0.029/0.049\n",
      "[16/50][1/1686] Loss_D: 0.043 Loss_G: 0.537 D(x): 0.974 D(G(z)): 0.277/0.146\n",
      "[16/50][101/1686] Loss_D: 0.038 Loss_G: 0.925 D(x): 1.000 D(G(z)): 0.202/0.174\n",
      "[16/50][201/1686] Loss_D: 0.021 Loss_G: 0.535 D(x): 0.936 D(G(z)): 0.272/0.196\n",
      "[16/50][301/1686] Loss_D: 0.053 Loss_G: 0.341 D(x): 0.920 D(G(z)): 0.097/0.143\n",
      "[16/50][401/1686] Loss_D: 0.119 Loss_G: 0.221 D(x): 1.044 D(G(z)): 0.202/0.247\n",
      "[16/50][501/1686] Loss_D: 0.059 Loss_G: 0.598 D(x): 1.015 D(G(z)): 0.207/0.090\n",
      "[16/50][601/1686] Loss_D: 0.024 Loss_G: 0.775 D(x): 1.001 D(G(z)): 0.182/0.250\n",
      "[16/50][701/1686] Loss_D: 0.023 Loss_G: 1.114 D(x): 1.073 D(G(z)): 0.171/0.107\n",
      "[16/50][801/1686] Loss_D: 0.017 Loss_G: 0.815 D(x): 0.903 D(G(z)): 0.096/0.087\n",
      "[16/50][901/1686] Loss_D: 0.176 Loss_G: 1.015 D(x): 0.763 D(G(z)): 0.040/0.148\n",
      "[16/50][1001/1686] Loss_D: 0.090 Loss_G: 0.327 D(x): 0.936 D(G(z)): 0.097/0.133\n",
      "[16/50][1101/1686] Loss_D: 0.062 Loss_G: 1.068 D(x): 0.985 D(G(z)): 0.255/0.108\n",
      "[16/50][1201/1686] Loss_D: 0.027 Loss_G: 0.622 D(x): 0.931 D(G(z)): 0.165/0.255\n",
      "[16/50][1301/1686] Loss_D: 0.107 Loss_G: 0.784 D(x): 0.978 D(G(z)): 0.318/0.310\n",
      "[16/50][1401/1686] Loss_D: 0.060 Loss_G: 0.433 D(x): 0.916 D(G(z)): 0.245/0.097\n",
      "[16/50][1501/1686] Loss_D: 0.096 Loss_G: 1.210 D(x): 0.875 D(G(z)): 0.108/0.067\n",
      "[16/50][1601/1686] Loss_D: 0.008 Loss_G: 0.770 D(x): 1.024 D(G(z)): 0.207/0.138\n",
      "[17/50][1/1686] Loss_D: 0.088 Loss_G: 0.379 D(x): 0.987 D(G(z)): 0.275/0.136\n",
      "[17/50][101/1686] Loss_D: 0.032 Loss_G: 0.402 D(x): 0.965 D(G(z)): 0.196/0.165\n",
      "[17/50][201/1686] Loss_D: 0.046 Loss_G: 0.847 D(x): 1.004 D(G(z)): 0.263/0.220\n",
      "[17/50][301/1686] Loss_D: 0.012 Loss_G: 0.671 D(x): 0.880 D(G(z)): 0.184/0.096\n",
      "[17/50][401/1686] Loss_D: 0.042 Loss_G: 0.812 D(x): 1.045 D(G(z)): 0.239/0.180\n",
      "[17/50][501/1686] Loss_D: 0.101 Loss_G: 1.094 D(x): 0.841 D(G(z)): 0.087/0.103\n",
      "[17/50][601/1686] Loss_D: 0.069 Loss_G: 0.226 D(x): 0.962 D(G(z)): 0.301/0.236\n",
      "[17/50][701/1686] Loss_D: 0.029 Loss_G: 0.737 D(x): 1.040 D(G(z)): 0.262/0.185\n",
      "[17/50][801/1686] Loss_D: 0.006 Loss_G: 0.601 D(x): 0.990 D(G(z)): 0.190/0.224\n",
      "[17/50][901/1686] Loss_D: 0.107 Loss_G: 0.854 D(x): 0.898 D(G(z)): 0.144/0.275\n",
      "[17/50][1001/1686] Loss_D: 0.044 Loss_G: 0.762 D(x): 0.990 D(G(z)): 0.251/0.180\n",
      "[17/50][1101/1686] Loss_D: 0.059 Loss_G: 0.980 D(x): 0.869 D(G(z)): -0.004/0.088\n",
      "[17/50][1201/1686] Loss_D: 0.015 Loss_G: 0.421 D(x): 0.984 D(G(z)): 0.240/0.269\n",
      "[17/50][1301/1686] Loss_D: 0.012 Loss_G: 0.524 D(x): 0.943 D(G(z)): 0.121/0.169\n",
      "[17/50][1401/1686] Loss_D: 0.099 Loss_G: 0.786 D(x): 0.894 D(G(z)): 0.028/0.148\n",
      "[17/50][1501/1686] Loss_D: 0.016 Loss_G: 0.500 D(x): 0.901 D(G(z)): 0.168/0.119\n",
      "[17/50][1601/1686] Loss_D: 0.028 Loss_G: 0.634 D(x): 0.863 D(G(z)): 0.146/0.178\n",
      "[18/50][1/1686] Loss_D: 0.059 Loss_G: 1.023 D(x): 1.078 D(G(z)): 0.237/0.137\n",
      "[18/50][101/1686] Loss_D: 0.014 Loss_G: 0.520 D(x): 0.859 D(G(z)): 0.151/0.059\n",
      "[18/50][201/1686] Loss_D: 0.075 Loss_G: 0.333 D(x): 1.041 D(G(z)): 0.283/0.238\n",
      "[18/50][301/1686] Loss_D: 0.068 Loss_G: 0.613 D(x): 0.884 D(G(z)): 0.251/0.145\n",
      "[18/50][401/1686] Loss_D: 0.019 Loss_G: 0.560 D(x): 0.882 D(G(z)): 0.233/0.158\n",
      "[18/50][501/1686] Loss_D: 0.080 Loss_G: 0.457 D(x): 0.967 D(G(z)): 0.222/0.074\n",
      "[18/50][601/1686] Loss_D: 0.026 Loss_G: 0.777 D(x): 0.937 D(G(z)): 0.175/0.166\n",
      "[18/50][701/1686] Loss_D: 0.048 Loss_G: 0.785 D(x): 0.970 D(G(z)): 0.244/0.123\n",
      "[18/50][801/1686] Loss_D: 0.083 Loss_G: 0.569 D(x): 0.990 D(G(z)): 0.180/0.004\n",
      "[18/50][901/1686] Loss_D: 0.010 Loss_G: 0.695 D(x): 1.110 D(G(z)): 0.225/0.257\n",
      "[18/50][1001/1686] Loss_D: 0.022 Loss_G: 0.761 D(x): 0.915 D(G(z)): 0.178/0.177\n",
      "[18/50][1101/1686] Loss_D: 0.034 Loss_G: 0.947 D(x): 0.984 D(G(z)): 0.177/0.154\n",
      "[18/50][1201/1686] Loss_D: 0.015 Loss_G: 0.688 D(x): 0.945 D(G(z)): 0.138/0.175\n",
      "[18/50][1301/1686] Loss_D: 0.022 Loss_G: 0.949 D(x): 0.922 D(G(z)): 0.004/0.023\n",
      "[18/50][1401/1686] Loss_D: 0.070 Loss_G: 0.563 D(x): 0.930 D(G(z)): -0.000/0.015\n",
      "[18/50][1501/1686] Loss_D: 0.069 Loss_G: 0.636 D(x): 0.911 D(G(z)): 0.254/0.364\n",
      "[18/50][1601/1686] Loss_D: 0.045 Loss_G: 0.848 D(x): 0.841 D(G(z)): 0.077/0.122\n",
      "[19/50][1/1686] Loss_D: 0.018 Loss_G: 0.811 D(x): 1.048 D(G(z)): 0.126/0.062\n",
      "[19/50][101/1686] Loss_D: 0.019 Loss_G: 0.530 D(x): 0.845 D(G(z)): 0.048/0.036\n",
      "[19/50][201/1686] Loss_D: 0.060 Loss_G: 0.543 D(x): 0.946 D(G(z)): 0.143/0.033\n",
      "[19/50][301/1686] Loss_D: 0.019 Loss_G: 0.620 D(x): 1.028 D(G(z)): 0.147/0.193\n",
      "[19/50][401/1686] Loss_D: 0.069 Loss_G: 0.474 D(x): 1.020 D(G(z)): 0.254/0.123\n",
      "[19/50][501/1686] Loss_D: 0.078 Loss_G: 0.780 D(x): 0.922 D(G(z)): 0.188/0.304\n",
      "[19/50][601/1686] Loss_D: 0.006 Loss_G: 0.350 D(x): 0.915 D(G(z)): 0.214/0.275\n",
      "[19/50][701/1686] Loss_D: 0.006 Loss_G: 0.887 D(x): 1.073 D(G(z)): 0.139/0.166\n",
      "[19/50][801/1686] Loss_D: 0.021 Loss_G: 0.900 D(x): 0.956 D(G(z)): 0.021/0.063\n",
      "[19/50][901/1686] Loss_D: 0.027 Loss_G: 0.646 D(x): 0.861 D(G(z)): 0.214/0.209\n",
      "[19/50][1001/1686] Loss_D: 0.056 Loss_G: 1.026 D(x): 0.972 D(G(z)): 0.098/0.179\n",
      "[19/50][1101/1686] Loss_D: 0.029 Loss_G: 0.517 D(x): 1.012 D(G(z)): 0.133/0.166\n",
      "[19/50][1201/1686] Loss_D: 0.081 Loss_G: 0.833 D(x): 0.832 D(G(z)): 0.124/0.191\n",
      "[19/50][1301/1686] Loss_D: 0.056 Loss_G: 0.402 D(x): 0.913 D(G(z)): 0.116/0.119\n",
      "[19/50][1401/1686] Loss_D: 0.025 Loss_G: 0.646 D(x): 0.963 D(G(z)): 0.165/0.124\n",
      "[19/50][1501/1686] Loss_D: 0.062 Loss_G: 0.633 D(x): 0.785 D(G(z)): 0.122/0.179\n",
      "[19/50][1601/1686] Loss_D: 0.012 Loss_G: 0.457 D(x): 0.959 D(G(z)): 0.168/0.193\n",
      "[20/50][1/1686] Loss_D: 0.031 Loss_G: 0.560 D(x): 0.830 D(G(z)): 0.255/0.151\n",
      "[20/50][101/1686] Loss_D: 0.005 Loss_G: 0.789 D(x): 0.947 D(G(z)): 0.077/0.100\n",
      "[20/50][201/1686] Loss_D: 0.063 Loss_G: 0.444 D(x): 1.113 D(G(z)): 0.242/0.209\n",
      "[20/50][301/1686] Loss_D: 0.073 Loss_G: 0.887 D(x): 0.977 D(G(z)): 0.126/0.243\n",
      "[20/50][401/1686] Loss_D: 0.047 Loss_G: 0.857 D(x): 1.047 D(G(z)): 0.222/0.083\n",
      "[20/50][501/1686] Loss_D: 0.084 Loss_G: 0.853 D(x): 0.848 D(G(z)): 0.079/0.174\n",
      "[20/50][601/1686] Loss_D: 0.010 Loss_G: 0.723 D(x): 0.954 D(G(z)): 0.213/0.187\n",
      "[20/50][701/1686] Loss_D: 0.005 Loss_G: 0.592 D(x): 0.997 D(G(z)): 0.233/0.204\n",
      "[20/50][801/1686] Loss_D: 0.044 Loss_G: 0.397 D(x): 0.955 D(G(z)): 0.186/0.127\n",
      "[20/50][901/1686] Loss_D: 0.031 Loss_G: 0.870 D(x): 0.906 D(G(z)): 0.089/0.134\n",
      "[20/50][1001/1686] Loss_D: 0.054 Loss_G: 1.137 D(x): 0.939 D(G(z)): 0.173/0.080\n",
      "[20/50][1101/1686] Loss_D: 0.010 Loss_G: 0.697 D(x): 0.799 D(G(z)): 0.093/0.018\n",
      "[20/50][1201/1686] Loss_D: 0.048 Loss_G: 0.461 D(x): 1.007 D(G(z)): 0.125/0.181\n",
      "[20/50][1301/1686] Loss_D: 0.019 Loss_G: 0.439 D(x): 0.878 D(G(z)): 0.120/0.158\n",
      "[20/50][1401/1686] Loss_D: 0.016 Loss_G: 0.907 D(x): 0.972 D(G(z)): 0.145/0.079\n",
      "[20/50][1501/1686] Loss_D: 0.044 Loss_G: 0.409 D(x): 0.929 D(G(z)): 0.240/0.139\n",
      "[20/50][1601/1686] Loss_D: 0.080 Loss_G: 1.037 D(x): 0.927 D(G(z)): 0.171/0.153\n",
      "[21/50][1/1686] Loss_D: 0.062 Loss_G: 0.396 D(x): 0.949 D(G(z)): 0.051/0.136\n",
      "[21/50][101/1686] Loss_D: 0.056 Loss_G: 0.526 D(x): 0.827 D(G(z)): 0.076/0.199\n",
      "[21/50][201/1686] Loss_D: 0.066 Loss_G: 0.649 D(x): 0.905 D(G(z)): 0.061/0.183\n",
      "[21/50][301/1686] Loss_D: 0.059 Loss_G: 0.771 D(x): 0.947 D(G(z)): 0.166/0.274\n",
      "[21/50][401/1686] Loss_D: 0.061 Loss_G: 0.822 D(x): 0.914 D(G(z)): 0.082/0.174\n",
      "[21/50][501/1686] Loss_D: 0.088 Loss_G: 0.301 D(x): 1.040 D(G(z)): 0.316/0.237\n",
      "[21/50][601/1686] Loss_D: 0.072 Loss_G: 0.454 D(x): 1.004 D(G(z)): 0.106/0.097\n",
      "[21/50][701/1686] Loss_D: 0.120 Loss_G: 0.871 D(x): 0.801 D(G(z)): 0.201/0.166\n",
      "[21/50][801/1686] Loss_D: 0.009 Loss_G: 0.763 D(x): 0.980 D(G(z)): 0.091/0.049\n",
      "[21/50][901/1686] Loss_D: 0.004 Loss_G: 0.682 D(x): 0.964 D(G(z)): 0.152/0.124\n",
      "[21/50][1001/1686] Loss_D: 0.014 Loss_G: 0.632 D(x): 0.841 D(G(z)): 0.039/0.066\n",
      "[21/50][1101/1686] Loss_D: 0.023 Loss_G: 0.492 D(x): 1.012 D(G(z)): 0.239/0.275\n",
      "[21/50][1201/1686] Loss_D: 0.052 Loss_G: 1.127 D(x): 0.941 D(G(z)): 0.120/0.088\n",
      "[21/50][1301/1686] Loss_D: 0.085 Loss_G: 0.606 D(x): 1.078 D(G(z)): 0.231/0.094\n",
      "[21/50][1401/1686] Loss_D: 0.026 Loss_G: 0.634 D(x): 0.859 D(G(z)): 0.139/0.026\n",
      "[21/50][1501/1686] Loss_D: 0.054 Loss_G: 1.126 D(x): 0.864 D(G(z)): 0.043/0.022\n",
      "[21/50][1601/1686] Loss_D: 0.025 Loss_G: 0.612 D(x): 0.967 D(G(z)): 0.094/0.048\n",
      "[22/50][1/1686] Loss_D: 0.093 Loss_G: 0.526 D(x): 0.931 D(G(z)): 0.062/0.026\n",
      "[22/50][101/1686] Loss_D: 0.030 Loss_G: 0.549 D(x): 1.049 D(G(z)): 0.271/0.188\n",
      "[22/50][201/1686] Loss_D: 0.021 Loss_G: 0.711 D(x): 0.960 D(G(z)): 0.060/0.072\n",
      "[22/50][301/1686] Loss_D: 0.093 Loss_G: 1.168 D(x): 0.855 D(G(z)): 0.052/0.072\n",
      "[22/50][401/1686] Loss_D: 0.009 Loss_G: 0.609 D(x): 0.865 D(G(z)): 0.060/0.088\n",
      "[22/50][501/1686] Loss_D: 0.062 Loss_G: 0.301 D(x): 1.020 D(G(z)): 0.353/0.271\n",
      "[22/50][601/1686] Loss_D: 0.109 Loss_G: 0.323 D(x): 0.985 D(G(z)): 0.297/0.188\n",
      "[22/50][701/1686] Loss_D: 0.074 Loss_G: 0.423 D(x): 0.952 D(G(z)): 0.246/0.138\n",
      "[22/50][801/1686] Loss_D: 0.008 Loss_G: 0.628 D(x): 0.958 D(G(z)): 0.208/0.177\n",
      "[22/50][901/1686] Loss_D: 0.063 Loss_G: 0.369 D(x): 0.978 D(G(z)): 0.230/0.159\n",
      "[22/50][1001/1686] Loss_D: 0.023 Loss_G: 0.521 D(x): 0.947 D(G(z)): 0.112/0.080\n",
      "[22/50][1101/1686] Loss_D: 0.016 Loss_G: 0.475 D(x): 0.945 D(G(z)): 0.264/0.327\n",
      "[22/50][1201/1686] Loss_D: 0.010 Loss_G: 0.478 D(x): 0.823 D(G(z)): 0.072/0.059\n",
      "[22/50][1301/1686] Loss_D: 0.108 Loss_G: 0.418 D(x): 1.027 D(G(z)): 0.251/0.134\n",
      "[22/50][1401/1686] Loss_D: 0.088 Loss_G: 0.695 D(x): 0.834 D(G(z)): 0.064/0.196\n",
      "[22/50][1501/1686] Loss_D: 0.043 Loss_G: 0.431 D(x): 0.907 D(G(z)): 0.109/0.092\n",
      "[22/50][1601/1686] Loss_D: 0.011 Loss_G: 0.571 D(x): 1.017 D(G(z)): 0.190/0.216\n",
      "[23/50][1/1686] Loss_D: 0.009 Loss_G: 0.336 D(x): 0.834 D(G(z)): 0.192/0.256\n",
      "[23/50][101/1686] Loss_D: 0.046 Loss_G: 0.827 D(x): 0.864 D(G(z)): 0.142/0.152\n",
      "[23/50][201/1686] Loss_D: 0.051 Loss_G: 0.522 D(x): 1.012 D(G(z)): 0.148/0.089\n",
      "[23/50][301/1686] Loss_D: 0.043 Loss_G: 0.277 D(x): 0.918 D(G(z)): 0.199/0.203\n",
      "[23/50][401/1686] Loss_D: 0.062 Loss_G: 0.362 D(x): 0.963 D(G(z)): 0.117/0.209\n",
      "[23/50][501/1686] Loss_D: 0.008 Loss_G: 0.555 D(x): 0.853 D(G(z)): 0.173/0.171\n",
      "[23/50][601/1686] Loss_D: 0.006 Loss_G: 0.543 D(x): 0.865 D(G(z)): 0.143/0.188\n",
      "[23/50][701/1686] Loss_D: 0.011 Loss_G: 0.356 D(x): 0.854 D(G(z)): 0.219/0.296\n",
      "[23/50][801/1686] Loss_D: 0.018 Loss_G: 0.526 D(x): 0.885 D(G(z)): 0.087/0.051\n",
      "[23/50][901/1686] Loss_D: 0.100 Loss_G: 0.343 D(x): 1.015 D(G(z)): 0.231/0.156\n",
      "[23/50][1001/1686] Loss_D: 0.007 Loss_G: 0.420 D(x): 0.819 D(G(z)): 0.134/0.133\n",
      "[23/50][1101/1686] Loss_D: 0.108 Loss_G: 0.367 D(x): 1.056 D(G(z)): 0.235/0.164\n",
      "[23/50][1201/1686] Loss_D: 0.012 Loss_G: 0.787 D(x): 0.965 D(G(z)): 0.105/0.098\n",
      "[23/50][1301/1686] Loss_D: 0.046 Loss_G: 0.324 D(x): 0.945 D(G(z)): 0.172/0.199\n",
      "[23/50][1401/1686] Loss_D: 0.089 Loss_G: 0.687 D(x): 0.879 D(G(z)): 0.076/0.244\n",
      "[23/50][1501/1686] Loss_D: 0.032 Loss_G: 0.458 D(x): 1.021 D(G(z)): 0.239/0.219\n",
      "[23/50][1601/1686] Loss_D: 0.072 Loss_G: 0.696 D(x): 0.876 D(G(z)): 0.058/0.179\n",
      "[24/50][1/1686] Loss_D: 0.039 Loss_G: 0.655 D(x): 1.108 D(G(z)): 0.270/0.224\n",
      "[24/50][101/1686] Loss_D: 0.070 Loss_G: 0.912 D(x): 0.864 D(G(z)): 0.133/0.158\n",
      "[24/50][201/1686] Loss_D: 0.043 Loss_G: 0.484 D(x): 0.865 D(G(z)): 0.073/0.088\n",
      "[24/50][301/1686] Loss_D: 0.046 Loss_G: 0.326 D(x): 0.923 D(G(z)): 0.158/0.178\n",
      "[24/50][401/1686] Loss_D: 0.055 Loss_G: 0.308 D(x): 0.937 D(G(z)): 0.145/0.210\n",
      "[24/50][501/1686] Loss_D: 0.007 Loss_G: 0.800 D(x): 0.906 D(G(z)): 0.032/0.015\n",
      "[24/50][601/1686] Loss_D: 0.140 Loss_G: 0.424 D(x): 1.080 D(G(z)): 0.187/0.079\n",
      "[24/50][701/1686] Loss_D: 0.012 Loss_G: 0.680 D(x): 0.885 D(G(z)): 0.111/0.095\n",
      "[24/50][801/1686] Loss_D: 0.015 Loss_G: 0.378 D(x): 0.949 D(G(z)): 0.220/0.239\n",
      "[24/50][901/1686] Loss_D: 0.007 Loss_G: 0.687 D(x): 0.922 D(G(z)): 0.092/0.066\n",
      "[24/50][1001/1686] Loss_D: 0.004 Loss_G: 0.752 D(x): 0.923 D(G(z)): 0.112/0.098\n",
      "[24/50][1101/1686] Loss_D: 0.134 Loss_G: 0.499 D(x): 1.050 D(G(z)): 0.166/0.013\n",
      "[24/50][1201/1686] Loss_D: 0.014 Loss_G: 0.671 D(x): 0.912 D(G(z)): 0.137/0.195\n",
      "[24/50][1301/1686] Loss_D: 0.020 Loss_G: 0.622 D(x): 0.953 D(G(z)): 0.179/0.243\n",
      "[24/50][1401/1686] Loss_D: 0.025 Loss_G: 0.848 D(x): 0.947 D(G(z)): 0.143/0.081\n",
      "[24/50][1501/1686] Loss_D: 0.025 Loss_G: 0.830 D(x): 1.027 D(G(z)): 0.230/0.261\n",
      "[24/50][1601/1686] Loss_D: 0.012 Loss_G: 0.575 D(x): 1.072 D(G(z)): 0.224/0.233\n",
      "[25/50][1/1686] Loss_D: 0.026 Loss_G: 0.691 D(x): 0.932 D(G(z)): 0.169/0.200\n",
      "[25/50][101/1686] Loss_D: 0.029 Loss_G: 0.905 D(x): 0.961 D(G(z)): 0.182/0.166\n",
      "[25/50][201/1686] Loss_D: 0.010 Loss_G: 0.487 D(x): 0.900 D(G(z)): 0.154/0.185\n",
      "[25/50][301/1686] Loss_D: 0.028 Loss_G: 0.669 D(x): 0.993 D(G(z)): 0.130/0.052\n",
      "[25/50][401/1686] Loss_D: 0.051 Loss_G: 0.828 D(x): 0.933 D(G(z)): 0.223/0.213\n",
      "[25/50][501/1686] Loss_D: 0.005 Loss_G: 0.695 D(x): 0.969 D(G(z)): 0.153/0.180\n",
      "[25/50][601/1686] Loss_D: 0.033 Loss_G: 0.388 D(x): 0.884 D(G(z)): 0.140/0.160\n",
      "[25/50][701/1686] Loss_D: 0.026 Loss_G: 0.367 D(x): 0.847 D(G(z)): 0.128/0.127\n",
      "[25/50][801/1686] Loss_D: 0.015 Loss_G: 0.452 D(x): 0.955 D(G(z)): 0.196/0.172\n",
      "[25/50][901/1686] Loss_D: 0.007 Loss_G: 0.573 D(x): 0.944 D(G(z)): 0.180/0.211\n",
      "[25/50][1001/1686] Loss_D: 0.081 Loss_G: 0.820 D(x): 1.143 D(G(z)): 0.296/0.185\n",
      "[25/50][1101/1686] Loss_D: 0.024 Loss_G: 0.801 D(x): 0.907 D(G(z)): 0.098/0.125\n",
      "[25/50][1201/1686] Loss_D: 0.087 Loss_G: 0.989 D(x): 0.828 D(G(z)): 0.137/0.089\n",
      "[25/50][1301/1686] Loss_D: 0.016 Loss_G: 0.573 D(x): 0.951 D(G(z)): 0.163/0.109\n",
      "[25/50][1401/1686] Loss_D: 0.013 Loss_G: 0.623 D(x): 0.876 D(G(z)): 0.046/0.028\n",
      "[25/50][1501/1686] Loss_D: 0.032 Loss_G: 0.891 D(x): 1.104 D(G(z)): 0.221/0.139\n",
      "[25/50][1601/1686] Loss_D: 0.061 Loss_G: 0.876 D(x): 0.910 D(G(z)): 0.160/0.220\n",
      "[26/50][1/1686] Loss_D: 0.041 Loss_G: 0.857 D(x): 0.958 D(G(z)): 0.190/0.207\n",
      "[26/50][101/1686] Loss_D: 0.064 Loss_G: 0.438 D(x): 1.014 D(G(z)): 0.279/0.177\n",
      "[26/50][201/1686] Loss_D: 0.009 Loss_G: 0.763 D(x): 1.104 D(G(z)): 0.234/0.225\n",
      "[26/50][301/1686] Loss_D: 0.008 Loss_G: 0.553 D(x): 0.895 D(G(z)): 0.134/0.094\n",
      "[26/50][401/1686] Loss_D: 0.006 Loss_G: 0.807 D(x): 0.946 D(G(z)): 0.090/0.113\n",
      "[26/50][501/1686] Loss_D: 0.043 Loss_G: 0.530 D(x): 0.969 D(G(z)): 0.141/0.088\n",
      "[26/50][601/1686] Loss_D: 0.016 Loss_G: 0.676 D(x): 0.997 D(G(z)): 0.164/0.112\n",
      "[26/50][701/1686] Loss_D: 0.020 Loss_G: 0.750 D(x): 0.927 D(G(z)): 0.151/0.129\n",
      "[26/50][801/1686] Loss_D: 0.036 Loss_G: 0.426 D(x): 0.904 D(G(z)): 0.136/0.082\n",
      "[26/50][901/1686] Loss_D: 0.047 Loss_G: 0.743 D(x): 0.892 D(G(z)): 0.066/0.159\n",
      "[26/50][1001/1686] Loss_D: 0.082 Loss_G: 0.918 D(x): 0.861 D(G(z)): 0.153/0.181\n",
      "[26/50][1101/1686] Loss_D: 0.069 Loss_G: 0.628 D(x): 1.083 D(G(z)): 0.217/0.117\n",
      "[26/50][1201/1686] Loss_D: 0.111 Loss_G: 1.089 D(x): 0.874 D(G(z)): 0.116/0.146\n",
      "[26/50][1301/1686] Loss_D: 0.068 Loss_G: 0.333 D(x): 0.910 D(G(z)): 0.121/0.125\n",
      "[26/50][1401/1686] Loss_D: 0.011 Loss_G: 0.573 D(x): 1.012 D(G(z)): 0.219/0.189\n",
      "[26/50][1501/1686] Loss_D: 0.070 Loss_G: 0.486 D(x): 0.951 D(G(z)): 0.117/0.016\n",
      "[26/50][1601/1686] Loss_D: 0.037 Loss_G: 0.716 D(x): 0.944 D(G(z)): 0.105/0.203\n",
      "[27/50][1/1686] Loss_D: 0.049 Loss_G: 0.395 D(x): 0.883 D(G(z)): 0.108/0.140\n",
      "[27/50][101/1686] Loss_D: 0.073 Loss_G: 1.115 D(x): 0.909 D(G(z)): 0.082/0.093\n",
      "[27/50][201/1686] Loss_D: 0.054 Loss_G: 0.845 D(x): 0.979 D(G(z)): 0.277/0.265\n",
      "[27/50][301/1686] Loss_D: 0.069 Loss_G: 0.939 D(x): 0.898 D(G(z)): 0.053/0.141\n",
      "[27/50][401/1686] Loss_D: 0.029 Loss_G: 0.954 D(x): 0.919 D(G(z)): 0.128/0.052\n",
      "[27/50][501/1686] Loss_D: 0.038 Loss_G: 0.447 D(x): 0.870 D(G(z)): 0.147/0.085\n",
      "[27/50][601/1686] Loss_D: 0.041 Loss_G: 0.439 D(x): 0.928 D(G(z)): 0.164/0.090\n",
      "[27/50][701/1686] Loss_D: 0.061 Loss_G: 0.550 D(x): 0.816 D(G(z)): 0.158/0.283\n",
      "[27/50][801/1686] Loss_D: 0.023 Loss_G: 0.718 D(x): 0.945 D(G(z)): 0.129/0.068\n",
      "[27/50][901/1686] Loss_D: 0.145 Loss_G: 1.009 D(x): 0.869 D(G(z)): 0.035/0.166\n",
      "[27/50][1001/1686] Loss_D: 0.070 Loss_G: 0.333 D(x): 0.978 D(G(z)): 0.155/0.163\n",
      "[27/50][1101/1686] Loss_D: 0.051 Loss_G: 0.740 D(x): 0.965 D(G(z)): 0.229/0.321\n",
      "[27/50][1201/1686] Loss_D: 0.059 Loss_G: 0.849 D(x): 0.937 D(G(z)): 0.233/0.216\n",
      "[27/50][1301/1686] Loss_D: 0.021 Loss_G: 0.704 D(x): 0.926 D(G(z)): 0.139/0.209\n",
      "[27/50][1401/1686] Loss_D: 0.021 Loss_G: 0.653 D(x): 1.016 D(G(z)): 0.138/0.125\n",
      "[27/50][1501/1686] Loss_D: 0.078 Loss_G: 1.050 D(x): 0.829 D(G(z)): 0.060/0.077\n",
      "[27/50][1601/1686] Loss_D: 0.057 Loss_G: 0.816 D(x): 0.891 D(G(z)): 0.180/0.224\n",
      "[28/50][1/1686] Loss_D: 0.105 Loss_G: 0.955 D(x): 0.963 D(G(z)): 0.261/0.193\n",
      "[28/50][101/1686] Loss_D: 0.025 Loss_G: 0.768 D(x): 0.870 D(G(z)): 0.141/0.024\n",
      "[28/50][201/1686] Loss_D: 0.020 Loss_G: 0.833 D(x): 0.997 D(G(z)): 0.218/0.220\n",
      "[28/50][301/1686] Loss_D: 0.015 Loss_G: 0.379 D(x): 0.964 D(G(z)): 0.231/0.259\n",
      "[28/50][401/1686] Loss_D: 0.042 Loss_G: 0.659 D(x): 0.901 D(G(z)): 0.070/0.126\n",
      "[28/50][501/1686] Loss_D: 0.007 Loss_G: 0.493 D(x): 0.905 D(G(z)): 0.212/0.232\n",
      "[28/50][601/1686] Loss_D: 0.038 Loss_G: 1.096 D(x): 1.044 D(G(z)): 0.171/0.135\n",
      "[28/50][701/1686] Loss_D: 0.040 Loss_G: 0.452 D(x): 0.899 D(G(z)): 0.138/0.051\n",
      "[28/50][801/1686] Loss_D: 0.028 Loss_G: 0.880 D(x): 0.817 D(G(z)): 0.025/0.013\n",
      "[28/50][901/1686] Loss_D: 0.027 Loss_G: 0.502 D(x): 0.848 D(G(z)): 0.073/0.089\n",
      "[28/50][1001/1686] Loss_D: 0.019 Loss_G: 0.576 D(x): 0.919 D(G(z)): 0.124/0.147\n",
      "[28/50][1101/1686] Loss_D: 0.030 Loss_G: 0.590 D(x): 0.961 D(G(z)): 0.120/0.187\n",
      "[28/50][1201/1686] Loss_D: 0.012 Loss_G: 0.789 D(x): 0.965 D(G(z)): 0.162/0.174\n",
      "[28/50][1301/1686] Loss_D: 0.140 Loss_G: 0.333 D(x): 1.065 D(G(z)): 0.193/0.126\n",
      "[28/50][1401/1686] Loss_D: 0.030 Loss_G: 0.547 D(x): 0.913 D(G(z)): 0.200/0.133\n",
      "[28/50][1501/1686] Loss_D: 0.054 Loss_G: 0.510 D(x): 1.023 D(G(z)): 0.106/0.092\n",
      "[28/50][1601/1686] Loss_D: 0.072 Loss_G: 0.789 D(x): 0.932 D(G(z)): 0.110/0.244\n",
      "[29/50][1/1686] Loss_D: 0.033 Loss_G: 0.883 D(x): 0.938 D(G(z)): 0.075/0.122\n",
      "[29/50][101/1686] Loss_D: 0.004 Loss_G: 0.663 D(x): 0.951 D(G(z)): 0.118/0.126\n",
      "[29/50][201/1686] Loss_D: 0.033 Loss_G: 0.557 D(x): 0.976 D(G(z)): 0.156/0.154\n",
      "[29/50][301/1686] Loss_D: 0.051 Loss_G: 0.391 D(x): 0.938 D(G(z)): 0.160/0.103\n",
      "[29/50][401/1686] Loss_D: 0.081 Loss_G: 0.922 D(x): 0.857 D(G(z)): 0.137/0.167\n",
      "[29/50][501/1686] Loss_D: 0.011 Loss_G: 0.744 D(x): 0.956 D(G(z)): 0.130/0.156\n",
      "[29/50][601/1686] Loss_D: 0.100 Loss_G: 0.785 D(x): 0.834 D(G(z)): 0.186/0.262\n",
      "[29/50][701/1686] Loss_D: 0.055 Loss_G: 0.542 D(x): 0.990 D(G(z)): 0.219/0.105\n",
      "[29/50][801/1686] Loss_D: 0.011 Loss_G: 0.682 D(x): 0.974 D(G(z)): 0.198/0.242\n",
      "[29/50][901/1686] Loss_D: 0.035 Loss_G: 0.377 D(x): 0.921 D(G(z)): 0.164/0.138\n",
      "[29/50][1001/1686] Loss_D: 0.091 Loss_G: 0.436 D(x): 0.965 D(G(z)): 0.059/0.043\n",
      "[29/50][1101/1686] Loss_D: 0.027 Loss_G: 0.873 D(x): 1.006 D(G(z)): 0.114/0.163\n",
      "[29/50][1201/1686] Loss_D: 0.021 Loss_G: 0.555 D(x): 0.854 D(G(z)): 0.133/0.190\n",
      "[29/50][1301/1686] Loss_D: 0.043 Loss_G: 0.425 D(x): 0.896 D(G(z)): 0.120/0.056\n",
      "[29/50][1401/1686] Loss_D: 0.024 Loss_G: 0.773 D(x): 1.042 D(G(z)): 0.235/0.254\n",
      "[29/50][1501/1686] Loss_D: 0.052 Loss_G: 0.812 D(x): 0.918 D(G(z)): 0.188/0.231\n",
      "[29/50][1601/1686] Loss_D: 0.014 Loss_G: 0.509 D(x): 0.894 D(G(z)): 0.120/0.082\n",
      "[30/50][1/1686] Loss_D: 0.016 Loss_G: 0.830 D(x): 0.957 D(G(z)): 0.135/0.134\n",
      "[30/50][101/1686] Loss_D: 0.049 Loss_G: 0.490 D(x): 0.942 D(G(z)): 0.102/0.137\n",
      "[30/50][201/1686] Loss_D: 0.034 Loss_G: 0.805 D(x): 1.020 D(G(z)): 0.284/0.291\n",
      "[30/50][301/1686] Loss_D: 0.022 Loss_G: 0.687 D(x): 0.886 D(G(z)): 0.115/0.155\n",
      "[30/50][401/1686] Loss_D: 0.018 Loss_G: 0.666 D(x): 0.972 D(G(z)): 0.145/0.129\n",
      "[30/50][501/1686] Loss_D: 0.081 Loss_G: 0.936 D(x): 0.875 D(G(z)): 0.158/0.183\n",
      "[30/50][601/1686] Loss_D: 0.012 Loss_G: 0.624 D(x): 1.002 D(G(z)): 0.162/0.130\n",
      "[30/50][701/1686] Loss_D: 0.053 Loss_G: 0.935 D(x): 0.920 D(G(z)): 0.152/0.169\n",
      "[30/50][801/1686] Loss_D: 0.017 Loss_G: 0.641 D(x): 0.915 D(G(z)): 0.126/0.045\n",
      "[30/50][901/1686] Loss_D: 0.030 Loss_G: 0.392 D(x): 0.956 D(G(z)): 0.194/0.164\n",
      "[30/50][1001/1686] Loss_D: 0.023 Loss_G: 0.412 D(x): 0.996 D(G(z)): 0.231/0.244\n",
      "[30/50][1101/1686] Loss_D: 0.043 Loss_G: 0.927 D(x): 0.938 D(G(z)): 0.078/0.130\n",
      "[30/50][1201/1686] Loss_D: 0.015 Loss_G: 0.436 D(x): 0.911 D(G(z)): 0.198/0.229\n",
      "[30/50][1301/1686] Loss_D: 0.108 Loss_G: 0.278 D(x): 1.027 D(G(z)): 0.231/0.177\n",
      "[30/50][1401/1686] Loss_D: 0.059 Loss_G: 0.594 D(x): 1.063 D(G(z)): 0.223/0.133\n",
      "[30/50][1501/1686] Loss_D: 0.026 Loss_G: 0.820 D(x): 0.976 D(G(z)): 0.178/0.151\n",
      "[30/50][1601/1686] Loss_D: 0.061 Loss_G: 0.891 D(x): 0.864 D(G(z)): 0.098/0.159\n",
      "[31/50][1/1686] Loss_D: 0.056 Loss_G: 0.684 D(x): 0.986 D(G(z)): 0.231/0.204\n",
      "[31/50][101/1686] Loss_D: 0.049 Loss_G: 0.396 D(x): 0.945 D(G(z)): 0.125/0.107\n",
      "[31/50][201/1686] Loss_D: 0.049 Loss_G: 0.614 D(x): 0.959 D(G(z)): 0.222/0.183\n",
      "[31/50][301/1686] Loss_D: 0.023 Loss_G: 0.681 D(x): 0.920 D(G(z)): 0.102/0.147\n",
      "[31/50][401/1686] Loss_D: 0.019 Loss_G: 0.884 D(x): 0.944 D(G(z)): 0.115/0.124\n",
      "[31/50][501/1686] Loss_D: 0.019 Loss_G: 0.484 D(x): 0.969 D(G(z)): 0.181/0.201\n",
      "[31/50][601/1686] Loss_D: 0.037 Loss_G: 0.785 D(x): 0.930 D(G(z)): 0.207/0.216\n",
      "[31/50][701/1686] Loss_D: 0.058 Loss_G: 0.874 D(x): 0.910 D(G(z)): 0.166/0.182\n",
      "[31/50][801/1686] Loss_D: 0.021 Loss_G: 0.643 D(x): 0.964 D(G(z)): 0.168/0.120\n",
      "[31/50][901/1686] Loss_D: 0.009 Loss_G: 0.680 D(x): 0.888 D(G(z)): 0.112/0.105\n",
      "[31/50][1001/1686] Loss_D: 0.009 Loss_G: 0.838 D(x): 0.966 D(G(z)): 0.126/0.126\n",
      "[31/50][1101/1686] Loss_D: 0.055 Loss_G: 0.407 D(x): 1.005 D(G(z)): 0.201/0.153\n",
      "[31/50][1201/1686] Loss_D: 0.022 Loss_G: 0.780 D(x): 0.992 D(G(z)): 0.220/0.227\n",
      "[31/50][1301/1686] Loss_D: 0.051 Loss_G: 0.566 D(x): 1.098 D(G(z)): 0.241/0.183\n",
      "[31/50][1401/1686] Loss_D: 0.007 Loss_G: 0.607 D(x): 0.965 D(G(z)): 0.200/0.221\n",
      "[31/50][1501/1686] Loss_D: 0.022 Loss_G: 0.589 D(x): 0.932 D(G(z)): 0.083/0.034\n",
      "[31/50][1601/1686] Loss_D: 0.049 Loss_G: 0.794 D(x): 0.944 D(G(z)): 0.125/0.215\n",
      "[32/50][1/1686] Loss_D: 0.059 Loss_G: 0.424 D(x): 0.931 D(G(z)): 0.210/0.134\n",
      "[32/50][101/1686] Loss_D: 0.016 Loss_G: 0.765 D(x): 0.929 D(G(z)): 0.117/0.090\n",
      "[32/50][201/1686] Loss_D: 0.036 Loss_G: 0.416 D(x): 0.970 D(G(z)): 0.252/0.186\n",
      "[32/50][301/1686] Loss_D: 0.038 Loss_G: 1.021 D(x): 0.957 D(G(z)): 0.113/0.134\n",
      "[32/50][401/1686] Loss_D: 0.094 Loss_G: 0.962 D(x): 0.909 D(G(z)): 0.059/0.122\n",
      "[32/50][501/1686] Loss_D: 0.066 Loss_G: 0.860 D(x): 0.846 D(G(z)): 0.050/0.128\n",
      "[32/50][601/1686] Loss_D: 0.007 Loss_G: 0.553 D(x): 0.961 D(G(z)): 0.200/0.187\n",
      "[32/50][701/1686] Loss_D: 0.035 Loss_G: 0.828 D(x): 0.948 D(G(z)): 0.171/0.177\n",
      "[32/50][801/1686] Loss_D: 0.007 Loss_G: 0.596 D(x): 0.943 D(G(z)): 0.167/0.207\n",
      "[32/50][901/1686] Loss_D: 0.003 Loss_G: 0.703 D(x): 0.964 D(G(z)): 0.115/0.104\n",
      "[32/50][1001/1686] Loss_D: 0.068 Loss_G: 0.882 D(x): 0.927 D(G(z)): 0.159/0.207\n",
      "[32/50][1101/1686] Loss_D: 0.019 Loss_G: 0.733 D(x): 0.978 D(G(z)): 0.209/0.188\n",
      "[32/50][1201/1686] Loss_D: 0.030 Loss_G: 0.374 D(x): 0.923 D(G(z)): 0.178/0.159\n",
      "[32/50][1301/1686] Loss_D: 0.009 Loss_G: 0.821 D(x): 0.927 D(G(z)): 0.122/0.114\n",
      "[32/50][1401/1686] Loss_D: 0.043 Loss_G: 0.480 D(x): 1.004 D(G(z)): 0.198/0.124\n",
      "[32/50][1501/1686] Loss_D: 0.025 Loss_G: 0.426 D(x): 0.887 D(G(z)): 0.150/0.088\n",
      "[32/50][1601/1686] Loss_D: 0.038 Loss_G: 0.383 D(x): 0.905 D(G(z)): 0.134/0.123\n",
      "[33/50][1/1686] Loss_D: 0.063 Loss_G: 0.746 D(x): 0.863 D(G(z)): 0.077/0.154\n",
      "[33/50][101/1686] Loss_D: 0.031 Loss_G: 0.921 D(x): 1.026 D(G(z)): 0.195/0.232\n",
      "[33/50][201/1686] Loss_D: 0.006 Loss_G: 0.694 D(x): 0.957 D(G(z)): 0.116/0.137\n",
      "[33/50][301/1686] Loss_D: 0.050 Loss_G: 0.638 D(x): 0.981 D(G(z)): 0.237/0.182\n",
      "[33/50][401/1686] Loss_D: 0.033 Loss_G: 0.427 D(x): 0.988 D(G(z)): 0.190/0.165\n",
      "[33/50][501/1686] Loss_D: 0.048 Loss_G: 0.964 D(x): 0.957 D(G(z)): 0.139/0.194\n",
      "[33/50][601/1686] Loss_D: 0.008 Loss_G: 0.523 D(x): 0.933 D(G(z)): 0.172/0.144\n",
      "[33/50][701/1686] Loss_D: 0.022 Loss_G: 0.721 D(x): 0.856 D(G(z)): 0.093/0.118\n",
      "[33/50][801/1686] Loss_D: 0.120 Loss_G: 1.117 D(x): 0.907 D(G(z)): 0.077/0.142\n",
      "[33/50][901/1686] Loss_D: 0.007 Loss_G: 0.492 D(x): 0.949 D(G(z)): 0.267/0.251\n",
      "[33/50][1001/1686] Loss_D: 0.081 Loss_G: 0.250 D(x): 0.948 D(G(z)): 0.262/0.205\n",
      "[33/50][1101/1686] Loss_D: 0.007 Loss_G: 0.477 D(x): 0.983 D(G(z)): 0.231/0.232\n",
      "[33/50][1201/1686] Loss_D: 0.053 Loss_G: 0.396 D(x): 1.003 D(G(z)): 0.157/0.149\n",
      "[33/50][1301/1686] Loss_D: 0.052 Loss_G: 0.482 D(x): 1.028 D(G(z)): 0.158/0.119\n",
      "[33/50][1401/1686] Loss_D: 0.096 Loss_G: 1.087 D(x): 0.867 D(G(z)): 0.128/0.127\n",
      "[33/50][1501/1686] Loss_D: 0.026 Loss_G: 0.432 D(x): 0.993 D(G(z)): 0.190/0.199\n",
      "[33/50][1601/1686] Loss_D: 0.013 Loss_G: 0.544 D(x): 0.920 D(G(z)): 0.124/0.087\n",
      "[34/50][1/1686] Loss_D: 0.079 Loss_G: 0.906 D(x): 0.893 D(G(z)): 0.048/0.128\n",
      "[34/50][101/1686] Loss_D: 0.042 Loss_G: 0.950 D(x): 0.988 D(G(z)): 0.141/0.201\n",
      "[34/50][201/1686] Loss_D: 0.044 Loss_G: 0.349 D(x): 0.957 D(G(z)): 0.191/0.192\n",
      "[34/50][301/1686] Loss_D: 0.053 Loss_G: 0.401 D(x): 0.939 D(G(z)): 0.102/0.090\n",
      "[34/50][401/1686] Loss_D: 0.019 Loss_G: 0.801 D(x): 0.965 D(G(z)): 0.171/0.175\n",
      "[34/50][501/1686] Loss_D: 0.027 Loss_G: 0.765 D(x): 0.944 D(G(z)): 0.089/0.136\n",
      "[34/50][601/1686] Loss_D: 0.029 Loss_G: 0.674 D(x): 0.930 D(G(z)): 0.123/0.160\n",
      "[34/50][701/1686] Loss_D: 0.075 Loss_G: 0.892 D(x): 0.925 D(G(z)): 0.124/0.184\n",
      "[34/50][801/1686] Loss_D: 0.043 Loss_G: 0.390 D(x): 0.953 D(G(z)): 0.159/0.178\n",
      "[34/50][901/1686] Loss_D: 0.033 Loss_G: 0.485 D(x): 0.909 D(G(z)): 0.150/0.104\n",
      "[34/50][1001/1686] Loss_D: 0.009 Loss_G: 0.499 D(x): 0.894 D(G(z)): 0.146/0.121\n",
      "[34/50][1101/1686] Loss_D: 0.004 Loss_G: 0.615 D(x): 1.008 D(G(z)): 0.215/0.240\n",
      "[34/50][1201/1686] Loss_D: 0.006 Loss_G: 0.626 D(x): 0.908 D(G(z)): 0.157/0.136\n",
      "[34/50][1301/1686] Loss_D: 0.015 Loss_G: 0.766 D(x): 0.888 D(G(z)): 0.105/0.127\n",
      "[34/50][1401/1686] Loss_D: 0.008 Loss_G: 0.870 D(x): 0.976 D(G(z)): 0.130/0.119\n",
      "[34/50][1501/1686] Loss_D: 0.025 Loss_G: 0.719 D(x): 0.864 D(G(z)): 0.137/0.169\n",
      "[34/50][1601/1686] Loss_D: 0.046 Loss_G: 0.900 D(x): 0.955 D(G(z)): 0.185/0.217\n",
      "[35/50][1/1686] Loss_D: 0.078 Loss_G: 0.871 D(x): 0.933 D(G(z)): 0.174/0.258\n",
      "[35/50][101/1686] Loss_D: 0.016 Loss_G: 0.589 D(x): 0.925 D(G(z)): 0.107/0.080\n",
      "[35/50][201/1686] Loss_D: 0.021 Loss_G: 0.600 D(x): 0.920 D(G(z)): 0.149/0.117\n",
      "[35/50][301/1686] Loss_D: 0.067 Loss_G: 0.927 D(x): 1.017 D(G(z)): 0.241/0.201\n",
      "[35/50][401/1686] Loss_D: 0.030 Loss_G: 0.553 D(x): 0.971 D(G(z)): 0.107/0.071\n",
      "[35/50][501/1686] Loss_D: 0.041 Loss_G: 0.923 D(x): 0.930 D(G(z)): 0.152/0.144\n",
      "[35/50][601/1686] Loss_D: 0.035 Loss_G: 0.380 D(x): 0.938 D(G(z)): 0.215/0.153\n",
      "[35/50][701/1686] Loss_D: 0.052 Loss_G: 0.442 D(x): 1.050 D(G(z)): 0.293/0.210\n",
      "[35/50][801/1686] Loss_D: 0.071 Loss_G: 1.074 D(x): 1.008 D(G(z)): 0.192/0.155\n",
      "[35/50][901/1686] Loss_D: 0.024 Loss_G: 0.750 D(x): 0.987 D(G(z)): 0.226/0.168\n",
      "[35/50][1001/1686] Loss_D: 0.024 Loss_G: 0.474 D(x): 0.916 D(G(z)): 0.134/0.106\n",
      "[35/50][1101/1686] Loss_D: 0.015 Loss_G: 0.757 D(x): 0.927 D(G(z)): 0.143/0.134\n",
      "[35/50][1201/1686] Loss_D: 0.119 Loss_G: 1.168 D(x): 0.832 D(G(z)): 0.051/0.094\n",
      "[35/50][1301/1686] Loss_D: 0.060 Loss_G: 0.380 D(x): 0.943 D(G(z)): 0.108/0.085\n",
      "[35/50][1401/1686] Loss_D: 0.057 Loss_G: 0.994 D(x): 0.948 D(G(z)): 0.087/0.151\n",
      "[35/50][1501/1686] Loss_D: 0.015 Loss_G: 0.483 D(x): 0.991 D(G(z)): 0.186/0.183\n",
      "[35/50][1601/1686] Loss_D: 0.026 Loss_G: 0.644 D(x): 0.908 D(G(z)): 0.144/0.188\n",
      "[36/50][1/1686] Loss_D: 0.034 Loss_G: 0.802 D(x): 1.028 D(G(z)): 0.254/0.292\n",
      "[36/50][101/1686] Loss_D: 0.023 Loss_G: 0.523 D(x): 0.961 D(G(z)): 0.147/0.104\n",
      "[36/50][201/1686] Loss_D: 0.041 Loss_G: 0.548 D(x): 0.889 D(G(z)): 0.101/0.128\n",
      "[36/50][301/1686] Loss_D: 0.011 Loss_G: 0.617 D(x): 0.806 D(G(z)): 0.059/0.065\n",
      "[36/50][401/1686] Loss_D: 0.027 Loss_G: 0.478 D(x): 0.854 D(G(z)): 0.055/0.012\n",
      "[36/50][501/1686] Loss_D: 0.045 Loss_G: 0.945 D(x): 0.929 D(G(z)): 0.135/0.134\n",
      "[36/50][601/1686] Loss_D: 0.114 Loss_G: 0.316 D(x): 1.046 D(G(z)): 0.250/0.173\n",
      "[36/50][701/1686] Loss_D: 0.025 Loss_G: 0.598 D(x): 0.998 D(G(z)): 0.239/0.193\n",
      "[36/50][801/1686] Loss_D: 0.015 Loss_G: 0.687 D(x): 0.960 D(G(z)): 0.152/0.138\n",
      "[36/50][901/1686] Loss_D: 0.016 Loss_G: 0.786 D(x): 0.950 D(G(z)): 0.136/0.161\n",
      "[36/50][1001/1686] Loss_D: 0.008 Loss_G: 0.629 D(x): 0.963 D(G(z)): 0.109/0.086\n",
      "[36/50][1101/1686] Loss_D: 0.010 Loss_G: 0.706 D(x): 0.956 D(G(z)): 0.171/0.188\n",
      "[36/50][1201/1686] Loss_D: 0.038 Loss_G: 0.458 D(x): 1.000 D(G(z)): 0.188/0.145\n",
      "[36/50][1301/1686] Loss_D: 0.048 Loss_G: 0.344 D(x): 0.925 D(G(z)): 0.150/0.123\n",
      "[36/50][1401/1686] Loss_D: 0.004 Loss_G: 0.599 D(x): 0.943 D(G(z)): 0.133/0.144\n",
      "[36/50][1501/1686] Loss_D: 0.014 Loss_G: 0.544 D(x): 1.027 D(G(z)): 0.193/0.187\n",
      "[36/50][1601/1686] Loss_D: 0.155 Loss_G: 0.392 D(x): 1.077 D(G(z)): 0.299/0.204\n",
      "[37/50][1/1686] Loss_D: 0.055 Loss_G: 0.300 D(x): 0.945 D(G(z)): 0.227/0.213\n",
      "[37/50][101/1686] Loss_D: 0.071 Loss_G: 0.295 D(x): 1.038 D(G(z)): 0.247/0.243\n",
      "[37/50][201/1686] Loss_D: 0.053 Loss_G: 0.469 D(x): 0.895 D(G(z)): 0.073/0.105\n",
      "[37/50][301/1686] Loss_D: 0.022 Loss_G: 0.783 D(x): 0.971 D(G(z)): 0.188/0.198\n",
      "[37/50][401/1686] Loss_D: 0.003 Loss_G: 0.548 D(x): 0.847 D(G(z)): 0.077/0.066\n",
      "[37/50][501/1686] Loss_D: 0.048 Loss_G: 0.959 D(x): 0.962 D(G(z)): 0.134/0.178\n",
      "[37/50][601/1686] Loss_D: 0.025 Loss_G: 0.714 D(x): 0.866 D(G(z)): 0.101/0.146\n",
      "[37/50][701/1686] Loss_D: 0.038 Loss_G: 1.057 D(x): 0.983 D(G(z)): 0.124/0.141\n",
      "[37/50][801/1686] Loss_D: 0.007 Loss_G: 0.551 D(x): 1.002 D(G(z)): 0.214/0.181\n",
      "[37/50][901/1686] Loss_D: 0.003 Loss_G: 0.472 D(x): 0.915 D(G(z)): 0.178/0.201\n",
      "[37/50][1001/1686] Loss_D: 0.034 Loss_G: 0.367 D(x): 0.972 D(G(z)): 0.198/0.214\n",
      "[37/50][1101/1686] Loss_D: 0.019 Loss_G: 0.840 D(x): 0.932 D(G(z)): 0.128/0.109\n",
      "[37/50][1201/1686] Loss_D: 0.032 Loss_G: 0.556 D(x): 0.928 D(G(z)): 0.065/0.023\n",
      "[37/50][1301/1686] Loss_D: 0.017 Loss_G: 0.629 D(x): 0.978 D(G(z)): 0.204/0.196\n",
      "[37/50][1401/1686] Loss_D: 0.003 Loss_G: 0.642 D(x): 0.983 D(G(z)): 0.207/0.207\n",
      "[37/50][1501/1686] Loss_D: 0.053 Loss_G: 0.426 D(x): 0.913 D(G(z)): 0.098/0.117\n",
      "[37/50][1601/1686] Loss_D: 0.073 Loss_G: 0.385 D(x): 0.971 D(G(z)): 0.162/0.115\n",
      "[38/50][1/1686] Loss_D: 0.005 Loss_G: 0.508 D(x): 0.932 D(G(z)): 0.203/0.192\n",
      "[38/50][101/1686] Loss_D: 0.055 Loss_G: 0.466 D(x): 0.917 D(G(z)): 0.094/0.118\n",
      "[38/50][201/1686] Loss_D: 0.031 Loss_G: 0.715 D(x): 0.920 D(G(z)): 0.075/0.075\n",
      "[38/50][301/1686] Loss_D: 0.108 Loss_G: 0.994 D(x): 0.900 D(G(z)): 0.091/0.177\n",
      "[38/50][401/1686] Loss_D: 0.062 Loss_G: 0.418 D(x): 0.965 D(G(z)): 0.103/0.082\n",
      "[38/50][501/1686] Loss_D: 0.024 Loss_G: 0.979 D(x): 1.077 D(G(z)): 0.200/0.145\n",
      "[38/50][601/1686] Loss_D: 0.026 Loss_G: 0.716 D(x): 0.888 D(G(z)): 0.196/0.172\n",
      "[38/50][701/1686] Loss_D: 0.060 Loss_G: 0.983 D(x): 0.974 D(G(z)): 0.171/0.196\n",
      "[38/50][801/1686] Loss_D: 0.003 Loss_G: 0.742 D(x): 1.015 D(G(z)): 0.191/0.193\n",
      "[38/50][901/1686] Loss_D: 0.095 Loss_G: 1.023 D(x): 0.865 D(G(z)): 0.132/0.147\n",
      "[38/50][1001/1686] Loss_D: 0.069 Loss_G: 1.036 D(x): 0.957 D(G(z)): 0.151/0.151\n",
      "[38/50][1101/1686] Loss_D: 0.007 Loss_G: 0.581 D(x): 0.921 D(G(z)): 0.102/0.101\n",
      "[38/50][1201/1686] Loss_D: 0.014 Loss_G: 0.727 D(x): 0.892 D(G(z)): 0.110/0.132\n",
      "[38/50][1301/1686] Loss_D: 0.059 Loss_G: 0.897 D(x): 0.854 D(G(z)): 0.104/0.146\n",
      "[38/50][1401/1686] Loss_D: 0.004 Loss_G: 0.564 D(x): 0.877 D(G(z)): 0.135/0.136\n",
      "[38/50][1501/1686] Loss_D: 0.036 Loss_G: 0.524 D(x): 0.913 D(G(z)): 0.115/0.144\n",
      "[38/50][1601/1686] Loss_D: 0.033 Loss_G: 0.966 D(x): 0.970 D(G(z)): 0.143/0.164\n",
      "[39/50][1/1686] Loss_D: 0.038 Loss_G: 0.819 D(x): 1.041 D(G(z)): 0.246/0.252\n",
      "[39/50][101/1686] Loss_D: 0.007 Loss_G: 0.666 D(x): 0.970 D(G(z)): 0.169/0.139\n",
      "[39/50][201/1686] Loss_D: 0.022 Loss_G: 0.632 D(x): 0.921 D(G(z)): 0.127/0.184\n",
      "[39/50][301/1686] Loss_D: 0.061 Loss_G: 0.378 D(x): 0.963 D(G(z)): 0.129/0.113\n",
      "[39/50][401/1686] Loss_D: 0.058 Loss_G: 0.442 D(x): 0.979 D(G(z)): 0.173/0.124\n",
      "[39/50][501/1686] Loss_D: 0.017 Loss_G: 0.581 D(x): 0.989 D(G(z)): 0.169/0.134\n",
      "[39/50][601/1686] Loss_D: 0.012 Loss_G: 0.534 D(x): 0.906 D(G(z)): 0.124/0.112\n",
      "[39/50][701/1686] Loss_D: 0.016 Loss_G: 0.414 D(x): 0.925 D(G(z)): 0.176/0.159\n",
      "[39/50][801/1686] Loss_D: 0.018 Loss_G: 0.524 D(x): 0.919 D(G(z)): 0.132/0.104\n",
      "[39/50][901/1686] Loss_D: 0.051 Loss_G: 0.773 D(x): 0.953 D(G(z)): 0.185/0.264\n",
      "[39/50][1001/1686] Loss_D: 0.010 Loss_G: 0.720 D(x): 0.973 D(G(z)): 0.156/0.174\n",
      "[39/50][1101/1686] Loss_D: 0.023 Loss_G: 0.359 D(x): 0.851 D(G(z)): 0.150/0.172\n",
      "[39/50][1201/1686] Loss_D: 0.051 Loss_G: 0.967 D(x): 0.898 D(G(z)): 0.118/0.131\n",
      "[39/50][1301/1686] Loss_D: 0.099 Loss_G: 1.160 D(x): 0.859 D(G(z)): 0.063/0.090\n",
      "[39/50][1401/1686] Loss_D: 0.056 Loss_G: 0.396 D(x): 0.906 D(G(z)): 0.111/0.131\n",
      "[39/50][1501/1686] Loss_D: 0.073 Loss_G: 0.358 D(x): 0.984 D(G(z)): 0.169/0.125\n",
      "[39/50][1601/1686] Loss_D: 0.052 Loss_G: 0.316 D(x): 0.932 D(G(z)): 0.167/0.176\n",
      "[40/50][1/1686] Loss_D: 0.039 Loss_G: 0.887 D(x): 0.979 D(G(z)): 0.171/0.206\n",
      "[40/50][101/1686] Loss_D: 0.033 Loss_G: 0.510 D(x): 1.055 D(G(z)): 0.236/0.194\n",
      "[40/50][201/1686] Loss_D: 0.021 Loss_G: 0.831 D(x): 0.946 D(G(z)): 0.159/0.128\n",
      "[40/50][301/1686] Loss_D: 0.078 Loss_G: 0.946 D(x): 0.982 D(G(z)): 0.225/0.204\n",
      "[40/50][401/1686] Loss_D: 0.029 Loss_G: 0.814 D(x): 0.984 D(G(z)): 0.210/0.236\n",
      "[40/50][501/1686] Loss_D: 0.072 Loss_G: 1.061 D(x): 0.890 D(G(z)): 0.075/0.120\n",
      "[40/50][601/1686] Loss_D: 0.056 Loss_G: 0.484 D(x): 1.019 D(G(z)): 0.198/0.158\n",
      "[40/50][701/1686] Loss_D: 0.046 Loss_G: 0.387 D(x): 0.944 D(G(z)): 0.131/0.115\n",
      "[40/50][801/1686] Loss_D: 0.028 Loss_G: 0.432 D(x): 0.953 D(G(z)): 0.179/0.197\n",
      "[40/50][901/1686] Loss_D: 0.039 Loss_G: 0.791 D(x): 0.913 D(G(z)): 0.062/0.084\n",
      "[40/50][1001/1686] Loss_D: 0.061 Loss_G: 0.382 D(x): 1.001 D(G(z)): 0.167/0.163\n",
      "[40/50][1101/1686] Loss_D: 0.022 Loss_G: 0.630 D(x): 0.819 D(G(z)): 0.083/0.098\n",
      "[40/50][1201/1686] Loss_D: 0.051 Loss_G: 0.863 D(x): 1.002 D(G(z)): 0.199/0.262\n",
      "[40/50][1301/1686] Loss_D: 0.020 Loss_G: 0.836 D(x): 1.026 D(G(z)): 0.217/0.208\n",
      "[40/50][1401/1686] Loss_D: 0.031 Loss_G: 0.778 D(x): 0.812 D(G(z)): 0.075/0.096\n",
      "[40/50][1501/1686] Loss_D: 0.074 Loss_G: 0.576 D(x): 1.000 D(G(z)): 0.269/0.231\n",
      "[40/50][1601/1686] Loss_D: 0.011 Loss_G: 0.620 D(x): 1.016 D(G(z)): 0.227/0.218\n",
      "[41/50][1/1686] Loss_D: 0.011 Loss_G: 0.531 D(x): 0.946 D(G(z)): 0.152/0.132\n",
      "[41/50][101/1686] Loss_D: 0.065 Loss_G: 0.496 D(x): 0.967 D(G(z)): 0.214/0.117\n",
      "[41/50][201/1686] Loss_D: 0.011 Loss_G: 0.737 D(x): 0.923 D(G(z)): 0.074/0.086\n",
      "[41/50][301/1686] Loss_D: 0.010 Loss_G: 0.698 D(x): 0.878 D(G(z)): 0.043/0.039\n",
      "[41/50][401/1686] Loss_D: 0.030 Loss_G: 0.767 D(x): 1.055 D(G(z)): 0.163/0.118\n",
      "[41/50][501/1686] Loss_D: 0.033 Loss_G: 0.404 D(x): 0.933 D(G(z)): 0.159/0.192\n",
      "[41/50][601/1686] Loss_D: 0.026 Loss_G: 0.413 D(x): 0.971 D(G(z)): 0.193/0.200\n",
      "[41/50][701/1686] Loss_D: 0.092 Loss_G: 0.276 D(x): 1.020 D(G(z)): 0.238/0.195\n",
      "[41/50][801/1686] Loss_D: 0.027 Loss_G: 0.650 D(x): 0.897 D(G(z)): 0.117/0.158\n",
      "[41/50][901/1686] Loss_D: 0.053 Loss_G: 0.955 D(x): 0.980 D(G(z)): 0.155/0.192\n",
      "[41/50][1001/1686] Loss_D: 0.011 Loss_G: 0.729 D(x): 0.901 D(G(z)): 0.134/0.124\n",
      "[41/50][1101/1686] Loss_D: 0.058 Loss_G: 0.980 D(x): 0.919 D(G(z)): 0.155/0.151\n",
      "[41/50][1201/1686] Loss_D: 0.050 Loss_G: 0.442 D(x): 0.997 D(G(z)): 0.145/0.157\n",
      "[41/50][1301/1686] Loss_D: 0.118 Loss_G: 0.268 D(x): 1.053 D(G(z)): 0.240/0.211\n",
      "[41/50][1401/1686] Loss_D: 0.022 Loss_G: 0.735 D(x): 0.877 D(G(z)): 0.092/0.101\n",
      "[41/50][1501/1686] Loss_D: 0.055 Loss_G: 0.885 D(x): 0.959 D(G(z)): 0.190/0.180\n",
      "[41/50][1601/1686] Loss_D: 0.070 Loss_G: 0.843 D(x): 0.843 D(G(z)): 0.163/0.183\n",
      "[42/50][1/1686] Loss_D: 0.034 Loss_G: 0.670 D(x): 1.051 D(G(z)): 0.252/0.227\n",
      "[42/50][101/1686] Loss_D: 0.047 Loss_G: 0.371 D(x): 0.814 D(G(z)): 0.079/0.097\n",
      "[42/50][201/1686] Loss_D: 0.087 Loss_G: 0.295 D(x): 0.964 D(G(z)): 0.149/0.167\n",
      "[42/50][301/1686] Loss_D: 0.021 Loss_G: 0.866 D(x): 0.987 D(G(z)): 0.167/0.179\n",
      "[42/50][401/1686] Loss_D: 0.017 Loss_G: 0.387 D(x): 0.934 D(G(z)): 0.195/0.208\n",
      "[42/50][501/1686] Loss_D: 0.020 Loss_G: 0.526 D(x): 1.025 D(G(z)): 0.250/0.208\n",
      "[42/50][601/1686] Loss_D: 0.025 Loss_G: 0.716 D(x): 0.959 D(G(z)): 0.206/0.178\n",
      "[42/50][701/1686] Loss_D: 0.010 Loss_G: 0.605 D(x): 1.043 D(G(z)): 0.188/0.174\n",
      "[42/50][801/1686] Loss_D: 0.051 Loss_G: 0.355 D(x): 0.913 D(G(z)): 0.142/0.156\n",
      "[42/50][901/1686] Loss_D: 0.017 Loss_G: 0.607 D(x): 1.019 D(G(z)): 0.174/0.182\n",
      "[42/50][1001/1686] Loss_D: 0.057 Loss_G: 0.282 D(x): 0.956 D(G(z)): 0.202/0.200\n",
      "[42/50][1101/1686] Loss_D: 0.050 Loss_G: 0.450 D(x): 0.903 D(G(z)): 0.118/0.033\n",
      "[42/50][1201/1686] Loss_D: 0.096 Loss_G: 0.371 D(x): 0.978 D(G(z)): 0.202/0.143\n",
      "[42/50][1301/1686] Loss_D: 0.028 Loss_G: 0.716 D(x): 0.917 D(G(z)): 0.115/0.148\n",
      "[42/50][1401/1686] Loss_D: 0.018 Loss_G: 0.497 D(x): 0.888 D(G(z)): 0.149/0.115\n",
      "[42/50][1501/1686] Loss_D: 0.014 Loss_G: 0.581 D(x): 0.994 D(G(z)): 0.237/0.180\n",
      "[42/50][1601/1686] Loss_D: 0.022 Loss_G: 0.707 D(x): 0.971 D(G(z)): 0.194/0.243\n",
      "[43/50][1/1686] Loss_D: 0.020 Loss_G: 0.695 D(x): 0.893 D(G(z)): 0.066/-0.007\n",
      "[43/50][101/1686] Loss_D: 0.063 Loss_G: 0.397 D(x): 0.976 D(G(z)): 0.144/0.107\n",
      "[43/50][201/1686] Loss_D: 0.033 Loss_G: 0.533 D(x): 0.976 D(G(z)): 0.174/0.155\n",
      "[43/50][301/1686] Loss_D: 0.007 Loss_G: 0.554 D(x): 0.890 D(G(z)): 0.125/0.129\n",
      "[43/50][401/1686] Loss_D: 0.028 Loss_G: 0.882 D(x): 1.016 D(G(z)): 0.218/0.233\n",
      "[43/50][501/1686] Loss_D: 0.049 Loss_G: 0.895 D(x): 0.955 D(G(z)): 0.124/0.172\n",
      "[43/50][601/1686] Loss_D: 0.102 Loss_G: 0.990 D(x): 0.954 D(G(z)): 0.211/0.186\n",
      "[43/50][701/1686] Loss_D: 0.002 Loss_G: 0.568 D(x): 0.934 D(G(z)): 0.157/0.157\n",
      "[43/50][801/1686] Loss_D: 0.007 Loss_G: 0.754 D(x): 0.918 D(G(z)): 0.092/0.100\n",
      "[43/50][901/1686] Loss_D: 0.041 Loss_G: 0.932 D(x): 0.928 D(G(z)): 0.126/0.122\n",
      "[43/50][1001/1686] Loss_D: 0.032 Loss_G: 0.417 D(x): 0.875 D(G(z)): 0.066/0.072\n",
      "[43/50][1101/1686] Loss_D: 0.058 Loss_G: 0.883 D(x): 0.941 D(G(z)): 0.199/0.169\n",
      "[43/50][1201/1686] Loss_D: 0.023 Loss_G: 0.728 D(x): 0.934 D(G(z)): 0.233/0.214\n",
      "[43/50][1301/1686] Loss_D: 0.048 Loss_G: 0.308 D(x): 0.973 D(G(z)): 0.243/0.213\n",
      "[43/50][1401/1686] Loss_D: 0.017 Loss_G: 0.807 D(x): 0.972 D(G(z)): 0.114/0.092\n",
      "[43/50][1501/1686] Loss_D: 0.050 Loss_G: 0.799 D(x): 0.979 D(G(z)): 0.200/0.185\n",
      "[43/50][1601/1686] Loss_D: 0.056 Loss_G: 0.872 D(x): 0.924 D(G(z)): 0.192/0.216\n",
      "[44/50][1/1686] Loss_D: 0.072 Loss_G: 0.408 D(x): 0.979 D(G(z)): 0.128/0.079\n",
      "[44/50][101/1686] Loss_D: 0.038 Loss_G: 0.429 D(x): 0.978 D(G(z)): 0.147/0.136\n",
      "[44/50][201/1686] Loss_D: 0.027 Loss_G: 0.574 D(x): 1.043 D(G(z)): 0.210/0.170\n",
      "[44/50][301/1686] Loss_D: 0.003 Loss_G: 0.659 D(x): 0.998 D(G(z)): 0.156/0.152\n",
      "[44/50][401/1686] Loss_D: 0.018 Loss_G: 0.871 D(x): 0.976 D(G(z)): 0.159/0.172\n",
      "[44/50][501/1686] Loss_D: 0.002 Loss_G: 0.699 D(x): 0.968 D(G(z)): 0.154/0.148\n",
      "[44/50][601/1686] Loss_D: 0.007 Loss_G: 0.593 D(x): 1.008 D(G(z)): 0.188/0.188\n",
      "[44/50][701/1686] Loss_D: 0.020 Loss_G: 0.660 D(x): 0.918 D(G(z)): 0.149/0.123\n",
      "[44/50][801/1686] Loss_D: 0.007 Loss_G: 0.613 D(x): 1.028 D(G(z)): 0.191/0.177\n",
      "[44/50][901/1686] Loss_D: 0.007 Loss_G: 0.701 D(x): 0.969 D(G(z)): 0.159/0.170\n",
      "[44/50][1001/1686] Loss_D: 0.022 Loss_G: 0.933 D(x): 0.918 D(G(z)): 0.015/0.049\n",
      "[44/50][1101/1686] Loss_D: 0.085 Loss_G: 0.395 D(x): 0.928 D(G(z)): 0.090/0.097\n",
      "[44/50][1201/1686] Loss_D: 0.016 Loss_G: 0.731 D(x): 0.933 D(G(z)): 0.167/0.189\n",
      "[44/50][1301/1686] Loss_D: 0.003 Loss_G: 0.674 D(x): 0.882 D(G(z)): 0.073/0.073\n",
      "[44/50][1401/1686] Loss_D: 0.043 Loss_G: 0.483 D(x): 1.003 D(G(z)): 0.217/0.189\n",
      "[44/50][1501/1686] Loss_D: 0.019 Loss_G: 0.446 D(x): 0.936 D(G(z)): 0.154/0.137\n",
      "[44/50][1601/1686] Loss_D: 0.002 Loss_G: 0.800 D(x): 1.031 D(G(z)): 0.155/0.161\n",
      "[45/50][1/1686] Loss_D: 0.032 Loss_G: 0.612 D(x): 0.923 D(G(z)): 0.130/0.172\n",
      "[45/50][101/1686] Loss_D: 0.033 Loss_G: 0.411 D(x): 0.965 D(G(z)): 0.152/0.152\n",
      "[45/50][201/1686] Loss_D: 0.022 Loss_G: 0.664 D(x): 0.914 D(G(z)): 0.131/0.138\n",
      "[45/50][301/1686] Loss_D: 0.037 Loss_G: 0.877 D(x): 0.979 D(G(z)): 0.194/0.223\n",
      "[45/50][401/1686] Loss_D: 0.098 Loss_G: 0.395 D(x): 0.972 D(G(z)): 0.099/0.094\n",
      "[45/50][501/1686] Loss_D: 0.047 Loss_G: 0.408 D(x): 1.035 D(G(z)): 0.233/0.199\n",
      "[45/50][601/1686] Loss_D: 0.036 Loss_G: 0.915 D(x): 1.014 D(G(z)): 0.196/0.226\n",
      "[45/50][701/1686] Loss_D: 0.010 Loss_G: 0.561 D(x): 0.951 D(G(z)): 0.142/0.123\n",
      "[45/50][801/1686] Loss_D: 0.023 Loss_G: 0.588 D(x): 0.942 D(G(z)): 0.130/0.079\n",
      "[45/50][901/1686] Loss_D: 0.067 Loss_G: 0.395 D(x): 0.967 D(G(z)): 0.127/0.086\n",
      "[45/50][1001/1686] Loss_D: 0.098 Loss_G: 0.383 D(x): 0.937 D(G(z)): 0.084/0.089\n",
      "[45/50][1101/1686] Loss_D: 0.006 Loss_G: 0.634 D(x): 0.908 D(G(z)): 0.115/0.095\n",
      "[45/50][1201/1686] Loss_D: 0.038 Loss_G: 0.444 D(x): 1.030 D(G(z)): 0.204/0.171\n",
      "[45/50][1301/1686] Loss_D: 0.112 Loss_G: 1.034 D(x): 0.891 D(G(z)): 0.072/0.130\n",
      "[45/50][1401/1686] Loss_D: 0.010 Loss_G: 0.774 D(x): 1.020 D(G(z)): 0.183/0.203\n",
      "[45/50][1501/1686] Loss_D: 0.058 Loss_G: 0.351 D(x): 0.929 D(G(z)): 0.171/0.135\n",
      "[45/50][1601/1686] Loss_D: 0.034 Loss_G: 0.542 D(x): 0.970 D(G(z)): 0.180/0.120\n",
      "[46/50][1/1686] Loss_D: 0.002 Loss_G: 0.705 D(x): 0.960 D(G(z)): 0.125/0.122\n",
      "[46/50][101/1686] Loss_D: 0.008 Loss_G: 0.662 D(x): 0.998 D(G(z)): 0.121/0.119\n",
      "[46/50][201/1686] Loss_D: 0.024 Loss_G: 0.430 D(x): 1.055 D(G(z)): 0.256/0.251\n",
      "[46/50][301/1686] Loss_D: 0.043 Loss_G: 0.971 D(x): 0.901 D(G(z)): 0.090/0.112\n",
      "[46/50][401/1686] Loss_D: 0.015 Loss_G: 0.647 D(x): 0.934 D(G(z)): 0.103/0.108\n",
      "[46/50][501/1686] Loss_D: 0.030 Loss_G: 0.804 D(x): 0.902 D(G(z)): 0.111/0.148\n",
      "[46/50][601/1686] Loss_D: 0.067 Loss_G: 0.887 D(x): 0.972 D(G(z)): 0.227/0.241\n",
      "[46/50][701/1686] Loss_D: 0.011 Loss_G: 0.740 D(x): 0.841 D(G(z)): 0.059/0.069\n",
      "[46/50][801/1686] Loss_D: 0.007 Loss_G: 0.663 D(x): 0.949 D(G(z)): 0.139/0.152\n",
      "[46/50][901/1686] Loss_D: 0.060 Loss_G: 0.358 D(x): 0.966 D(G(z)): 0.150/0.149\n",
      "[46/50][1001/1686] Loss_D: 0.003 Loss_G: 0.613 D(x): 0.881 D(G(z)): 0.086/0.093\n",
      "[46/50][1101/1686] Loss_D: 0.006 Loss_G: 0.704 D(x): 1.001 D(G(z)): 0.194/0.200\n",
      "[46/50][1201/1686] Loss_D: 0.092 Loss_G: 0.344 D(x): 1.011 D(G(z)): 0.178/0.131\n",
      "[46/50][1301/1686] Loss_D: 0.036 Loss_G: 0.427 D(x): 0.915 D(G(z)): 0.128/0.089\n",
      "[46/50][1401/1686] Loss_D: 0.017 Loss_G: 0.557 D(x): 0.881 D(G(z)): 0.129/0.167\n",
      "[46/50][1501/1686] Loss_D: 0.020 Loss_G: 0.657 D(x): 0.936 D(G(z)): 0.128/0.160\n",
      "[46/50][1601/1686] Loss_D: 0.002 Loss_G: 0.715 D(x): 0.979 D(G(z)): 0.143/0.144\n",
      "[47/50][1/1686] Loss_D: 0.057 Loss_G: 0.355 D(x): 0.978 D(G(z)): 0.203/0.175\n",
      "[47/50][101/1686] Loss_D: 0.011 Loss_G: 0.806 D(x): 1.004 D(G(z)): 0.183/0.203\n",
      "[47/50][201/1686] Loss_D: 0.021 Loss_G: 0.506 D(x): 0.937 D(G(z)): 0.169/0.123\n",
      "[47/50][301/1686] Loss_D: 0.029 Loss_G: 0.416 D(x): 0.973 D(G(z)): 0.175/0.177\n",
      "[47/50][401/1686] Loss_D: 0.121 Loss_G: 0.364 D(x): 1.021 D(G(z)): 0.178/0.104\n",
      "[47/50][501/1686] Loss_D: 0.037 Loss_G: 0.561 D(x): 0.991 D(G(z)): 0.123/0.127\n",
      "[47/50][601/1686] Loss_D: 0.001 Loss_G: 0.709 D(x): 0.966 D(G(z)): 0.134/0.132\n",
      "[47/50][701/1686] Loss_D: 0.042 Loss_G: 0.380 D(x): 0.826 D(G(z)): 0.087/0.108\n",
      "[47/50][801/1686] Loss_D: 0.072 Loss_G: 1.088 D(x): 0.922 D(G(z)): 0.116/0.128\n",
      "[47/50][901/1686] Loss_D: 0.037 Loss_G: 0.409 D(x): 0.962 D(G(z)): 0.169/0.150\n",
      "[47/50][1001/1686] Loss_D: 0.031 Loss_G: 0.768 D(x): 0.902 D(G(z)): 0.172/0.185\n",
      "[47/50][1101/1686] Loss_D: 0.057 Loss_G: 0.950 D(x): 0.907 D(G(z)): 0.143/0.164\n",
      "[47/50][1201/1686] Loss_D: 0.044 Loss_G: 0.804 D(x): 0.863 D(G(z)): 0.121/0.150\n",
      "[47/50][1301/1686] Loss_D: 0.031 Loss_G: 0.929 D(x): 0.981 D(G(z)): 0.165/0.177\n",
      "[47/50][1401/1686] Loss_D: 0.022 Loss_G: 0.550 D(x): 0.978 D(G(z)): 0.232/0.204\n",
      "[47/50][1501/1686] Loss_D: 0.034 Loss_G: 0.986 D(x): 1.012 D(G(z)): 0.171/0.167\n",
      "[47/50][1601/1686] Loss_D: 0.067 Loss_G: 0.905 D(x): 0.950 D(G(z)): 0.159/0.214\n",
      "[48/50][1/1686] Loss_D: 0.012 Loss_G: 0.768 D(x): 1.012 D(G(z)): 0.208/0.230\n",
      "[48/50][101/1686] Loss_D: 0.005 Loss_G: 0.653 D(x): 1.029 D(G(z)): 0.196/0.183\n",
      "[48/50][201/1686] Loss_D: 0.017 Loss_G: 0.467 D(x): 0.983 D(G(z)): 0.198/0.193\n",
      "[48/50][301/1686] Loss_D: 0.039 Loss_G: 0.901 D(x): 0.939 D(G(z)): 0.143/0.152\n",
      "[48/50][401/1686] Loss_D: 0.035 Loss_G: 0.429 D(x): 0.941 D(G(z)): 0.154/0.157\n",
      "[48/50][501/1686] Loss_D: 0.023 Loss_G: 0.416 D(x): 0.928 D(G(z)): 0.162/0.157\n",
      "[48/50][601/1686] Loss_D: 0.027 Loss_G: 0.828 D(x): 0.971 D(G(z)): 0.143/0.180\n",
      "[48/50][701/1686] Loss_D: 0.039 Loss_G: 0.441 D(x): 0.927 D(G(z)): 0.229/0.174\n",
      "[48/50][801/1686] Loss_D: 0.046 Loss_G: 0.875 D(x): 1.016 D(G(z)): 0.194/0.181\n",
      "[48/50][901/1686] Loss_D: 0.032 Loss_G: 0.822 D(x): 0.898 D(G(z)): 0.130/0.151\n",
      "[48/50][1001/1686] Loss_D: 0.027 Loss_G: 0.755 D(x): 0.983 D(G(z)): 0.211/0.260\n",
      "[48/50][1101/1686] Loss_D: 0.004 Loss_G: 0.701 D(x): 0.950 D(G(z)): 0.114/0.110\n",
      "[48/50][1201/1686] Loss_D: 0.099 Loss_G: 1.023 D(x): 0.889 D(G(z)): 0.144/0.187\n",
      "[48/50][1301/1686] Loss_D: 0.027 Loss_G: 0.455 D(x): 0.958 D(G(z)): 0.153/0.161\n",
      "[48/50][1401/1686] Loss_D: 0.047 Loss_G: 1.001 D(x): 0.964 D(G(z)): 0.151/0.168\n",
      "[48/50][1501/1686] Loss_D: 0.110 Loss_G: 0.385 D(x): 1.034 D(G(z)): 0.201/0.141\n",
      "[48/50][1601/1686] Loss_D: 0.047 Loss_G: 0.977 D(x): 0.944 D(G(z)): 0.163/0.171\n",
      "[49/50][1/1686] Loss_D: 0.065 Loss_G: 0.374 D(x): 1.040 D(G(z)): 0.245/0.194\n",
      "[49/50][101/1686] Loss_D: 0.004 Loss_G: 0.710 D(x): 0.911 D(G(z)): 0.090/0.113\n",
      "[49/50][201/1686] Loss_D: 0.021 Loss_G: 0.532 D(x): 0.902 D(G(z)): 0.161/0.201\n",
      "[49/50][301/1686] Loss_D: 0.016 Loss_G: 0.729 D(x): 0.916 D(G(z)): 0.142/0.173\n",
      "[49/50][401/1686] Loss_D: 0.024 Loss_G: 0.531 D(x): 0.982 D(G(z)): 0.134/0.108\n",
      "[49/50][501/1686] Loss_D: 0.012 Loss_G: 0.794 D(x): 0.925 D(G(z)): 0.137/0.134\n",
      "[49/50][601/1686] Loss_D: 0.032 Loss_G: 0.395 D(x): 0.899 D(G(z)): 0.137/0.146\n",
      "[49/50][701/1686] Loss_D: 0.055 Loss_G: 0.872 D(x): 0.963 D(G(z)): 0.220/0.257\n",
      "[49/50][801/1686] Loss_D: 0.013 Loss_G: 0.471 D(x): 1.002 D(G(z)): 0.199/0.214\n",
      "[49/50][901/1686] Loss_D: 0.056 Loss_G: 0.975 D(x): 0.903 D(G(z)): 0.133/0.130\n",
      "[49/50][1001/1686] Loss_D: 0.046 Loss_G: 0.843 D(x): 0.945 D(G(z)): 0.144/0.173\n",
      "[49/50][1101/1686] Loss_D: 0.019 Loss_G: 0.918 D(x): 0.959 D(G(z)): 0.113/0.121\n",
      "[49/50][1201/1686] Loss_D: 0.035 Loss_G: 0.501 D(x): 0.934 D(G(z)): 0.081/0.109\n",
      "[49/50][1301/1686] Loss_D: 0.037 Loss_G: 0.772 D(x): 0.871 D(G(z)): 0.085/0.113\n",
      "[49/50][1401/1686] Loss_D: 0.036 Loss_G: 0.758 D(x): 0.973 D(G(z)): 0.208/0.269\n",
      "[49/50][1501/1686] Loss_D: 0.006 Loss_G: 0.647 D(x): 0.965 D(G(z)): 0.178/0.193\n",
      "[49/50][1601/1686] Loss_D: 0.007 Loss_G: 0.757 D(x): 0.917 D(G(z)): 0.111/0.078\n",
      "[50/50][1/1686] Loss_D: 0.029 Loss_G: 0.586 D(x): 0.891 D(G(z)): 0.113/0.092\n",
      "[50/50][101/1686] Loss_D: 0.012 Loss_G: 0.728 D(x): 1.012 D(G(z)): 0.208/0.172\n",
      "[50/50][201/1686] Loss_D: 0.030 Loss_G: 0.451 D(x): 1.015 D(G(z)): 0.179/0.174\n",
      "[50/50][301/1686] Loss_D: 0.023 Loss_G: 0.440 D(x): 0.974 D(G(z)): 0.187/0.169\n",
      "[50/50][401/1686] Loss_D: 0.090 Loss_G: 1.021 D(x): 0.901 D(G(z)): 0.152/0.132\n",
      "[50/50][501/1686] Loss_D: 0.045 Loss_G: 0.441 D(x): 1.014 D(G(z)): 0.175/0.147\n",
      "[50/50][601/1686] Loss_D: 0.012 Loss_G: 0.536 D(x): 0.976 D(G(z)): 0.176/0.166\n",
      "[50/50][701/1686] Loss_D: 0.008 Loss_G: 0.824 D(x): 0.912 D(G(z)): 0.072/0.082\n",
      "[50/50][801/1686] Loss_D: 0.054 Loss_G: 0.961 D(x): 0.997 D(G(z)): 0.162/0.200\n",
      "[50/50][901/1686] Loss_D: 0.048 Loss_G: 0.292 D(x): 0.957 D(G(z)): 0.220/0.208\n",
      "[50/50][1001/1686] Loss_D: 0.036 Loss_G: 0.459 D(x): 0.981 D(G(z)): 0.186/0.142\n",
      "[50/50][1101/1686] Loss_D: 0.038 Loss_G: 0.917 D(x): 0.935 D(G(z)): 0.156/0.168\n",
      "[50/50][1201/1686] Loss_D: 0.063 Loss_G: 0.995 D(x): 0.920 D(G(z)): 0.154/0.163\n",
      "[50/50][1301/1686] Loss_D: 0.014 Loss_G: 0.454 D(x): 0.870 D(G(z)): 0.122/0.113\n",
      "[50/50][1401/1686] Loss_D: 0.043 Loss_G: 0.368 D(x): 0.909 D(G(z)): 0.130/0.137\n",
      "[50/50][1501/1686] Loss_D: 0.032 Loss_G: 0.763 D(x): 0.918 D(G(z)): 0.160/0.200\n",
      "[50/50][1601/1686] Loss_D: 0.029 Loss_G: 0.403 D(x): 0.902 D(G(z)): 0.121/0.128\n"
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "n_epoch = 50\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "D_loss_var = []\n",
    "for epoch in range(n_epoch):\n",
    "    #D_loss_sum = 0\n",
    "    #G_loss_sum = 0\n",
    "    D_sum = []\n",
    "    G_sum = []\n",
    "    for itr, data in enumerate(dataloaders['train']):\n",
    "        real_image = data[0].to(device)     # 元配列\n",
    "        #print(real_image)\n",
    "        sample_size = real_image.size(0)    # 配列数\n",
    "        noise = torch.randn(sample_size, nz, 1, device=device)   # 正規分布からノイズを生成\n",
    "        \n",
    "        real_target = torch.full((sample_size,), random.uniform(0.7, 1.2), device=device)     # 元配列に対する識別信号の目標値「1」\n",
    "        fake_target = torch.full((sample_size,), random.uniform(0.0, 0.3), device=device)     # 贋作配列に対する識別信号の目標値「0」\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        netD.zero_grad()    # 勾配の初期化\n",
    "\n",
    "        output = netD(real_image)   # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_real = criterion(output, real_target)  # 元配列に対する識別信号の損失値\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = netG(noise)    # 生成器Gでノイズから贋作配列を生成\n",
    "        #print(fake_image.detach())\n",
    "        output = netD(fake_image.detach())  # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_fake = criterion(output, fake_target)  # 贋作配列に対する識別信号の損失値\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
    "        #D_loss_sum += errD\n",
    "        D_sum.append(errD.cpu().detach().numpy())\n",
    "        #print(\"D_sum is\",D_sum)\n",
    "        errD.backward()    # 誤差逆伝播\n",
    "        optimizerD.step()   # Dのパラメーターを更新\n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        netG.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作配列に対する識別信号を出力\n",
    "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作配列を元配列と誤認させたいため目標値は「1」\n",
    "        #G_loss_sum += errG\n",
    "        G_sum.append(errG.cpu().detach().numpy())\n",
    "        #print(errG.cpu().detach().numpy())\n",
    "        #print(\"G_sum is\",G_sum)\n",
    "        errG.backward()     # 誤差逆伝播\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        optimizerG.step()   # Gのパラメータを更新\n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloaders['train']),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0:     # 初回に元配列を保存する\n",
    "            sem.vec2seq_save(\"real_pos_seq\", real_image.cpu(), 1)\n",
    "\n",
    "        #print(\"[\",itr,\"] SUM_lossD:\",D_loss_sum)\n",
    "        #print(\"[\",itr,\"] SUM_lossG:\",G_loss_sum)\n",
    "    ############################\n",
    "    # Lossの保存\n",
    "    ############################\n",
    "    #print(\"epoch\",epoch+1,\"D_loss is\",D_loss)\n",
    "    #print(\"epoch\",epoch+1,\"D_mean is\",mean(list(map(float, D_sum))))\n",
    "    #print(\"epoch\",epoch+1,\"G_loss is\",G_loss)\n",
    "    #print(\"epoch\",epoch+1,\"G_mean is\",mean(list(map(float, G_sum))))\n",
    "    D_loss.append(mean(list(map(float, D_sum)))) #1epochごとのDiscreminaterのLossの平均を格納\n",
    "    G_loss.append(mean(list(map(float, G_sum)))) #1epochごとのGeneratorのLossの平均を格納\n",
    "    D_loss_var.append(variance(list(map(float, D_sum))))\n",
    "    #print(\"D_losses\",D_loss)\n",
    "    #print(\"G_losses\",G_loss)\n",
    "    #print(fake_image.detach())\n",
    "#     vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "#                       normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用の配列生成とその配列の保存\n",
    "    ############################\n",
    "#     if (epoch + 1) % 5 == 0:   # 5エポックごとにfakeseqを保存する\n",
    "#         filename = 'fake_pos_seq_epoch' + str(epoch + 1)\n",
    "#         fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作配列を生成する\n",
    "#         sem.vec2seq_save(filename, fake_image.cpu().detach(), batch_size)\n",
    "#         output_fasta = 'fake_fasta' + str(epoch + 1)\n",
    "#         optional_name = 'fakeEpoch' + str(epoch + 1) + '_'\n",
    "#         sem.txt2fasta(filename, output_fasta, optional_name)\n",
    "#         torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "#         torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "\n",
    "############################\n",
    "# 結果の表示\n",
    "############################\n",
    "# x_num = np.arange(1,n_epoch + 1)\n",
    "# #print(x_num)\n",
    "# matplotlib.style.use('ggplot')\n",
    "# fig1, DGx = plt.subplots()\n",
    "\n",
    "# DGx.set_xlabel('epoch')\n",
    "# DGx.set_ylabel('Loss')\n",
    "\n",
    "# DGx.plot(x_num,D_loss,label='Discriminator Loss')\n",
    "# DGx.plot(x_num,G_loss,label='Generater Loss')\n",
    "# DGx.legend(loc = 'best')\n",
    "\n",
    "# DGx.set_title('Losses of Discriminator and Generater')\n",
    "# plt.title('Losses of Discreminater and Generater')\n",
    "\n",
    "# fig2, Var = plt.subplots()\n",
    "# Var.set_xlabel('epoch')\n",
    "# Var.set_ylabel('Var')\n",
    "\n",
    "# Var.plot(x_num,D_loss_var,label='Variance of Discriminator')\n",
    "# Var.legend(loc = 'best')\n",
    "\n",
    "# plt.show\n",
    "\n",
    "# fig1.savefig('Losses.png')\n",
    "# fig2.savefig('Dis_Var.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jIOzZdu6zyw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSGAN_ver2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
