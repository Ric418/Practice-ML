{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "76DG_1bf64GT",
    "outputId": "901d18fc-2089-4942-8535-d03b30a06363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1547759165030,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "vkzAllIK66ms",
    "outputId": "95793c99-a6ac-40f6-c1fb-67f75a880de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/Colab Notebooks/Practice-ML/Grad_thesis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46937,
     "status": "ok",
     "timestamp": 1547759210592,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "2L53fqQ67E7e",
    "outputId": "628e1b19-9b90-4407-f618-095ca2ce7572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.9)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (5.3.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPE7EzB96zyT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "from statistics import mean, variance, stdev\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models, transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seq_net import weights_init, Generator, Discriminator\n",
    "import seq_modules as sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48895,
     "status": "ok",
     "timestamp": 1547759212587,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zO4Zlp_46zyY",
    "outputId": "c23f7c24-a098-4efd-e492-f1feb39cbee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2547acd2410>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設定\n",
    "workers = 0\n",
    "batch_size=32\n",
    "nz = 100\n",
    "nch_g = 128\n",
    "nch_d = 128\n",
    "n_epoch = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "outf = './Result/lsGAN'\n",
    "display_interval = 100\n",
    "\n",
    "# 保存先ディレクトリを作成\n",
    "try:\n",
    "    os.makedirs(outf, exist_ok=True)\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    pass\n",
    "\n",
    "# 乱数のシード（種）を固定\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pS2Hwb06zyd"
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 128\n",
    "\n",
    "def make_dataset(datadir):\n",
    "    '''\n",
    "    convert sequence to vector array\n",
    "    1.init array all 0 (4*SEQ_LENGTH)\n",
    "    2.convert sequences (all 0 array) to vector array.\n",
    "    ex. ACCGAT =\n",
    "    0 0 0 0 0 0    1 0 0 0 1 0\n",
    "    0 0 0 0 0 0  → 0 1 1 0 0 0\n",
    "    0 0 0 0 0 0    0 0 0 1 0 0\n",
    "    0 0 0 0 0 0    0 0 0 0 0 1\n",
    "    '''\n",
    "    pos_seq = \"SRX356455.05_peak_seq_128.txt\"\n",
    "    # id      chr     start   end     seq\n",
    "    data = pd.read_csv(os.path.join(datadir, \"sequences\", pos_seq), sep=\"\\t\")\n",
    "    sequences = [] \n",
    "    classes = [] #positive or negative\n",
    "    for index, row in data[[\"id\", \"seq\"]].iterrows():\n",
    "        y = 1 #positive\n",
    "        seq_vector = seq2vector(row[\"seq\"])\n",
    "        if len(seq_vector) == 0:\n",
    "            continue\n",
    "        sequences.append(seq2vector(row[\"seq\"]))\n",
    "        classes.append(np.array(y))\n",
    "    return sequences, classes\n",
    "\n",
    "def seq2vector(seq):\n",
    "    if type(seq) is not str: # Case on Null sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = np.zeros((4, SEQ_LENGTH)) #initiallize 4*SEQ_LENGTH array all 0\n",
    "    flag = 0\n",
    "    for i in range(SEQ_LENGTH):\n",
    "        s = seq[i]\n",
    "        if s == \"a\" or s == \"A\":\n",
    "            seq_array[0, i] = 1\n",
    "        elif s == \"c\" or s == \"C\":\n",
    "            seq_array[1, i] = 1\n",
    "        elif s == \"g\" or s == \"G\":\n",
    "            seq_array[2, i] = 1\n",
    "        elif s == \"t\" or s == \"T\":\n",
    "            seq_array[3, i] = 1\n",
    "        else:\n",
    "            flag += 1\n",
    "    if len(seq) == flag: # Case on N sequence\n",
    "        return np.zeros((0,0))\n",
    "    seq_array = seq_array.astype(np.float32)\n",
    "    return seq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80045,
     "status": "ok",
     "timestamp": 1547759243762,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "Q3F_XWIE6zyg",
    "outputId": "be6f1ed4-58d5-4382-bf74-5df47583877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "datadir = \"data\"\n",
    "\n",
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transforms = transforms.Compose([\n",
    "            ToTensorOfTarget()\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        sample = self.transforms(sample)\n",
    "        target = self.targets[index]\n",
    "        target = self.transforms(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data 相当。\n",
    "X, y = make_dataset(datadir)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.01)\n",
    "\n",
    "\n",
    "sequence_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train),\n",
    "    'test': DatasetFolder(X_test, y_test)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEJXjMwVG_pO"
   },
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める配列をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=32\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        sequence_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(sequence_datasets[x]) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86262,
     "status": "ok",
     "timestamp": 1547759249997,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "THWJ0sN36zyk",
    "outputId": "d949d121-77fa-4106-c4a8-39a52414fa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): ConvTranspose1d(100, 2048, kernel_size=(4,), stride=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): ConvTranspose1d(2048, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): ConvTranspose1d(1024, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): ConvTranspose1d(512, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer5): Sequential(\n",
      "      (0): ConvTranspose1d(128, 4, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 生成器G。ランダムベクトルから贋作画像を生成する\n",
    "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
    "netG.apply(weights_init)    # weights_init関数で初期化\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86685,
     "status": "ok",
     "timestamp": 1547759250430,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "zIsEJjBi6zyn",
    "outputId": "15be38a4-b909-46fa-e9f0-f43285d3979b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (layers): ModuleDict(\n",
      "    (layer0): Sequential(\n",
      "      (0): Conv1d(4, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Conv1d(256, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Conv1d(1024, 2048, kernel_size=(4,), stride=(2,), padding=(1,))\n",
      "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (layer5): Conv1d(2048, 1, kernel_size=(4,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 識別器D。配列が、元配列か贋作配列かを識別する\n",
    "netD = Discriminator(nch_d=nch_d).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abf1PyD96zyq"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
    "\n",
    "# オプティマイザ−のセットアップ\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1,  device=device)  # 確認用の固定したノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1431,
     "status": "error",
     "timestamp": 1547757532865,
     "user": {
      "displayName": "Takuma Kobayashi",
      "photoUrl": "https://lh6.googleusercontent.com/-p-aKe8JYv6k/AAAAAAAAAAI/AAAAAAAAAB4/GxwcHgOFD6c/s64/photo.jpg",
      "userId": "06358397516930507128"
     },
     "user_tz": -540
    },
    "id": "dbEMPfif6zyt",
    "outputId": "86de345c-27ff-4713-bf12-91e13f2e0f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50][1/1686] Loss_D: 3.331 Loss_G: 37.502 D(x): 0.097 D(G(z)): 0.028/2.896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-aee0a6524060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print(fake_image.detach())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 識別器Dで元配列に対する識別信号を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0merrD_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_target\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 贋作配列に対する識別信号の損失値\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mD_G_z1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2154\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2156\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習のループ\n",
    "n_epoch = 50\n",
    "D_loss = []\n",
    "G_loss = []\n",
    "D_mean = []\n",
    "G_mean = []\n",
    "# D_loss_var = []\n",
    "for epoch in range(n_epoch):\n",
    "    #D_loss_sum = 0\n",
    "    #G_loss_sum = 0\n",
    "    for itr, data in enumerate(dataloaders['train']):\n",
    "        real_image = data[0].to(device)     # 元配列\n",
    "        #print(real_image)\n",
    "        sample_size = real_image.size(0)    # 配列数\n",
    "        noise = torch.randn(sample_size, nz, 1, device=device)   # 正規分布からノイズを生成\n",
    "        \n",
    "        real_target = torch.full((sample_size,), 1., device=device)     # 元配列に対する識別信号の目標値「1」\n",
    "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作配列に対する識別信号の目標値「0」\n",
    "        \n",
    "        ############################\n",
    "        # 識別器Dの更新\n",
    "        ###########################\n",
    "        netD.zero_grad()    # 勾配の初期化\n",
    "\n",
    "        output = netD(real_image)   # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_real = criterion(output, real_target)  # 元配列に対する識別信号の損失値\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake_image = netG(noise)    # 生成器Gでノイズから贋作配列を生成\n",
    "        #print(fake_image.detach())\n",
    "        output = netD(fake_image.detach())  # 識別器Dで元配列に対する識別信号を出力\n",
    "        errD_fake = criterion(output, fake_target)  # 贋作配列に対する識別信号の損失値\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
    "        D_loss.append(errD.cpu().detach().numpy()) #DiscreminatorのLossを格納\n",
    "        errD.backward()    # 誤差逆伝播\n",
    "        optimizerD.step()   # Dのパラメーターを更新\n",
    "\n",
    "        ############################\n",
    "        # 生成器Gの更新\n",
    "        ###########################\n",
    "        netG.zero_grad()    # 勾配の初期化\n",
    "        \n",
    "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作配列に対する識別信号を出力\n",
    "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作配列を元配列と誤認させたいため目標値は「1」\n",
    "        #G_loss_sum += errG\n",
    "        G_loss.append(errG.cpu().detach().numpy()) #GeneratorのLossを格納\n",
    "        #print(errG.cpu().detach().numpy())\n",
    "        #print(\"G_sum is\",G_sum)\n",
    "        errG.backward()     # 誤差逆伝播\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()   # Gのパラメータを更新\n",
    "\n",
    "        if itr % display_interval == 0: \n",
    "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
    "                  .format(epoch + 1, n_epoch,\n",
    "                          itr + 1, len(dataloaders['train']),\n",
    "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if epoch == 0 and itr == 0:     # 初回に元配列を保存する\n",
    "            #sem.vec2seq_save(\"real_pos_seq\", real_image.cpu(), 1)\n",
    "            D_mean.append(mean(list(map(float, D_loss))))\n",
    "            G_mean.append(mean(list(map(float, G_loss))))\n",
    "            \n",
    "        if len(D_loss) % 1000 == 0:\n",
    "            D_mean.append(mean(list(map(float, D_loss))))\n",
    "            G_mean.append(mean(list(map(float, G_loss))))\n",
    "            print(\"D_mean is\",D_mean)\n",
    "            print(\"G_mean is\",G_mean)\n",
    "        #print(\"[\",itr,\"] SUM_lossD:\",D_loss_sum)\n",
    "        #print(\"[\",itr,\"] SUM_lossG:\",G_loss_sum)\n",
    "    ############################\n",
    "    # Lossの保存\n",
    "    ############################\n",
    "    #print(\"epoch\",epoch+1,\"D_loss is\",D_loss)\n",
    "    #print(\"epoch\",epoch+1,\"D_mean is\",mean(list(map(float, D_sum))))\n",
    "    #print(\"epoch\",epoch+1,\"G_loss is\",G_loss)\n",
    "    #print(\"epoch\",epoch+1,\"G_mean is\",mean(list(map(float, G_sum))))\n",
    "    #D_loss_var.append(variance(list(map(float, D_sum))))\n",
    "    #print(\"D_losses\",D_loss)\n",
    "    #print(\"G_losses\",G_loss)\n",
    "    #print(fake_image.detach())\n",
    "#     vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
    "#                       normalize=True, nrow=10)\n",
    "\n",
    "    ############################\n",
    "    # 確認用の配列生成とその配列の保存\n",
    "    ############################\n",
    "        \n",
    "#     if (epoch + 1) % 5 == 0:   # 5エポックごとにfakeseqを保存する\n",
    "#         filename = 'fake_pos_seq_epoch' + str(epoch + 1)\n",
    "#         fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作配列を生成する\n",
    "#         sem.vec2seq_save(filename, fake_image.cpu().detach(), batch_size)\n",
    "#         torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
    "#         torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator's variance is 0.07710132563150868\n",
      "Generater's variance is 0.23971615942702987\n",
      "Discriminator's stdev is 0.27767125460066744\n",
      "Generater's stdev is 0.4896081692813447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "# 結果の表示\n",
    "############################\n",
    "\n",
    "print(\"Discriminator's variance is\",variance(list(map(float, D_loss))))\n",
    "print(\"Generater's variance is\",variance(list(map(float, G_loss))))\n",
    "print(\"Discriminator's stdev is\",stdev(list(map(float, D_loss))))\n",
    "print(\"Generater's stdev is\",stdev(list(map(float, G_loss))))\n",
    "\n",
    "x_num = list(map(lambda x: x*1000, np.arange(0,len(D_mean))))\n",
    "#print(x_num)\n",
    "matplotlib.style.use('ggplot')\n",
    "fig1, Dx = plt.subplots()\n",
    "Dx.set_xlabel('iteration')\n",
    "Dx.set_ylabel('Loss')\n",
    "Dx.plot(x_num,D_mean,label='Discriminator Loss')\n",
    "Dx.plot(x_num,G_mean,label='Generater Loss')\n",
    "Dx.legend(loc = 'best')\n",
    "Dx.set_title('')\n",
    "\n",
    "plt.xticks(np.arange(0, 84000 + 1, 10000))\n",
    "plt.title('')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig('iterAdam&Tanh&LeakyDGLosses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jIOzZdu6zyw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSGAN_ver2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
